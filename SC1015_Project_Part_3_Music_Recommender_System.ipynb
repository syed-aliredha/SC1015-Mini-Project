{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d8f22e",
   "metadata": {
    "id": "67d8f22e"
   },
   "source": [
    "# SC1015 Mini-Project: Spotify Music Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec94ad2",
   "metadata": {
    "id": "cec94ad2"
   },
   "source": [
    "### By FDDA Group 5\n",
    "Syed Ali Redha Alsagoff, Huang Yongjian, Ma Jinlin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481a8b9",
   "metadata": {
    "id": "5481a8b9"
   },
   "source": [
    "## Our problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2c81c",
   "metadata": {
    "id": "08a2c81c"
   },
   "source": [
    "Our simple question of what determines a user's music preference actually has important implications in real life! With our project, we aim to find out **how companies can maximise the use of machine learning techniques to recommend songs**. To streamline the efficiency aspect, we will also look into **what features make a good recommender system**, as well as **what model to use in a genre classification model**.\n",
    "<br>\n",
    "<br>\n",
    "A good genre prediction model is important due to the **lack of robust datasets with labelled genres**. Even in some research literatures on music recommender systems, the teams made use of genre classification models in their approaches.\n",
    "<br>\n",
    "<br>\n",
    "We believe that this is an important issue to tackle because of **the vast amount of features used in music recommender systems**. Novel approaches to recommender systems make use of Deep learning that engineer even more features for their system[1]. Advanced recommendation systems can make use of many features[2], in the realm of hundreds to even thousands of features to make their recommendations. Hence, to improve the efficiency and resource management, and possibly the quality of recommendations as well, **good feature selection** is paramount to any music streaming service company, such as Spotify.\n",
    "<br>\n",
    "<br>\n",
    "We will be using different feature selection techniques and will be evaluating our model trained using different feature selection techniques.\n",
    "<br>\n",
    "<br>\n",
    "Due to time and hardware and other resource constraints, we will be doing our project using a smaller set of features than what is typically used. Larger models make use of more features such as lyric data (making use of tokenisers), audio data (making use of RNNs and LSTMs) and user-item correlation features, and more. However, the techniques that we use here would be **easily extendable** to datasets that make use of features on the scale of hundreds or even thousands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J_tFzw8jswgr",
   "metadata": {
    "id": "J_tFzw8jswgr"
   },
   "source": [
    "## Installing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d97173",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36d97173",
    "outputId": "1810d7f7-c474-4b3a-c4ca-3f19579cdd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (1.13.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy scipy scikit-learn threadpoolctl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "QL4XdZKwBVLc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QL4XdZKwBVLc",
    "outputId": "fa6dabae-b37a-437b-9761-7e0208f982f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from xgboost) (1.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sjiUnmHZJx7c",
   "metadata": {
    "id": "sjiUnmHZJx7c"
   },
   "source": [
    "* Note you may need to restart your kernel after running the cell below, we need to get the latest versions of the following libraries for our code to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "qRe9Cj9Y89Cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRe9Cj9Y89Cb",
    "outputId": "149a328e-939c-4fab-d11d-3e9cbf11ef23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (3.8.4)\n",
      "Requirement already satisfied: seaborn in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9710fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d9710fd",
    "outputId": "4b8f6179-fb10-4707-a1d1-e2337015617a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spotipy in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (2.23.0)\n",
      "Requirement already satisfied: redis>=3.5.3 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from spotipy) (5.0.3)\n",
      "Requirement already satisfied: requests>=2.25.0 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from spotipy) (2.31.0)\n",
      "Requirement already satisfied: six>=1.15.0 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from spotipy) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from spotipy) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Jt6THQBMLQj0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jt6THQBMLQj0",
    "outputId": "f133fa4a-89af-4bd0-8bbd-336d3efcd1ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-pandas in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from sklearn-pandas) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.5.1 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from sklearn-pandas) (1.13.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from sklearn-pandas) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from sklearn-pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->sklearn-pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->sklearn-pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->sklearn-pandas) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.23.0->sklearn-pandas) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.23.0->sklearn-pandas) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/syed_aliredha/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->sklearn-pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ba670f",
   "metadata": {
    "id": "e2ba670f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syed_aliredha/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "\n",
    "# Libraries for extracting dataset\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time\n",
    "\n",
    "# Models use for EDA and light ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# Library and functions for getting pretrained models and mapper\n",
    "import pickle\n",
    "\n",
    "# Libraries for Feature Engineering (Genre Classification), and data preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, StandardScaler, MinMaxScaler\n",
    "\n",
    "# Libraries for our autoencoder model\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# For our Recommender System\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3DE50cAz80K",
   "metadata": {
    "id": "m3DE50cAz80K"
   },
   "source": [
    "# Our dataset for recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-u-Wik2a00hT",
   "metadata": {
    "id": "-u-Wik2a00hT"
   },
   "source": [
    "In this section, we will be detailing how we made our dataset to recommend songs to users. Spotify does not give access to all of its songs through its API, so we made our own dataset, using popular songs from a variety of genres for maximum coverage. To provide some simplicity, we constrained to system to recommend only English songs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Op0HPQRALgCZ",
   "metadata": {
    "id": "Op0HPQRALgCZ"
   },
   "source": [
    "### Function to extract playlist information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1yzy5tsU8BT7",
   "metadata": {
    "id": "1yzy5tsU8BT7"
   },
   "outputs": [],
   "source": [
    "def fetch_playlist_tracks(playlist_id, sp):\n",
    "    track_uris = []\n",
    "    artist_uris = []\n",
    "    track_names = []\n",
    "    artist_names = []\n",
    "    track_popularities = []\n",
    "    release_years = []\n",
    "    explicit_statuses = []\n",
    "    results = sp.playlist_tracks(playlist_id)\n",
    "    tracks = results['items']\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "    for item in tracks:\n",
    "        track = item['track']\n",
    "        if track:\n",
    "            track_uris.append(track['uri'])\n",
    "            track_names.append(track['name'])\n",
    "            artist_uris.extend([artist['uri'] for artist in track['artists']])\n",
    "            artist_names.append(track['artists'][0]['name'] if track['artists'] else 'Unknown')\n",
    "            track_popularities.append(track['popularity'])\n",
    "            explicit_statuses.append(track['explicit'])\n",
    "            release_date = track['album']['release_date']\n",
    "            release_year = release_date.split(\"-\")[0] if release_date else 'Unknown'\n",
    "            release_years.append(release_year)\n",
    "    return track_uris, track_names, artist_names, track_popularities, release_years, explicit_statuses\n",
    "\n",
    "def get_audio_info_from_playlist(playlist_id, sp):\n",
    "    tracks, track_names, artist_names, popularities, release_years, explicit_statuses = fetch_playlist_tracks(playlist_id, sp)\n",
    "    combined_data = []\n",
    "\n",
    "    for i in range(0, len(tracks), 50):\n",
    "        track_interval = tracks[i:i+50]\n",
    "        track_name_interval = track_names[i:i+50]\n",
    "        artist_name_interval = artist_names[i:i+50]\n",
    "        popularity_interval = popularities[i:i+50]\n",
    "        release_year_interval = release_years[i:i+50]\n",
    "        explicit_status_interval = explicit_statuses[i:i+50]\n",
    "\n",
    "        if not track_interval:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            audio_features = sp.audio_features(track_interval)\n",
    "        except spotipy.SpotifyException as e:\n",
    "            if e.http_status == 429:\n",
    "                print(f\"Rate limit exceeded, sleeping for {retry_after} seconds\")\n",
    "                time.sleep(retry_after)\n",
    "                # Exponential Backoff to comply with Spotify rate limits\n",
    "                retry_after = min(retry_after * 2, 64)\n",
    "            elif e.http_status == 400:\n",
    "                print(f\"Error with batch {i} to {i + len(track_interval) - 1}: {e.msg}, skipping...\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Unhandled error: {e}\")\n",
    "                continue\n",
    "\n",
    "        audio_features_batch = [\n",
    "            [track_name_interval[j], artist_name_interval[j], popularity_interval[j], release_year_interval[j], explicit_status_interval[j]] +\n",
    "            [v for k, v in d.items() if k not in ['type', 'id', 'uri', 'track_href', 'analysis_url']]\n",
    "            for j, d in enumerate(audio_features) if d is not None]\n",
    "\n",
    "        for features in audio_features_batch:\n",
    "            combined_data.append(features)\n",
    "\n",
    "    columns = ['Track Name', 'artists', 'popularity', 'release_year', 'explicit', 'danceability', 'energy', 'key', 'loudness',\n",
    "               'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n",
    "    return pd.DataFrame(combined_data, columns=columns)\n",
    "\n",
    "# Please use the developer ID and secret attached in the NTULearn submission\n",
    "# Feel free to running the code but sometimes there might be error due too too many requests, this may be due to\n",
    "# Spotify API temporarily banning the account from using its data\n",
    "client_id = ''  \n",
    "client_secret = ''\n",
    "auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager, requests_timeout=10, retries=5, status_forcelist=(429, 500, 502, 503, 504), backoff_factor=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8A5EknF3reB",
   "metadata": {
    "id": "a8A5EknF3reB"
   },
   "source": [
    "Above are the functions to extract the dataset from our playlists. We make use of the get_audio_info_from_playlist() function that makes use of the fetch_playlist_tracks() helper function. We then stored the resulting dataframe as a CSV file to import to this notebook.\n",
    "<br>\n",
    "<br>\n",
    "To save you time, we have already saved the dataset into 2 separate CSVs (Since spotify's limit on playlist is 10000 songs) but feel free to try and extract it using these uris:\n",
    "1. spotify:playlist:3Om5x2SLDI2QRnXOXNuTPo\n",
    "2. spotify:playlist:2YHkCdEuQ9hKoZZjJXsAS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b445318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = get_audio_info_from_playlist(\"(insert the playlist uri here)\",sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb2094",
   "metadata": {},
   "source": [
    "If you'd like, you could uncomment the code above and try adding in different playlist uris to extract their information into the test_df DataFrame. You can get playlist uris by simply going to your playlist on desktop and hovering share. If you press the option(for mac) or control(for windows) button, you can see the copy link button change to copy playlist uri."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84dea01",
   "metadata": {
    "id": "e84dea01"
   },
   "source": [
    "### Extracting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Lxvy8HFL-yOk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lxvy8HFL-yOk",
    "outputId": "6ef62259-5e18-490e-87c0-6e0d408773e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11794, 19)\n"
     ]
    }
   ],
   "source": [
    "full_dataset_df1 = pd.read_csv('spotify_playlist_dataset.csv')\n",
    "full_dataset_df2 = pd.read_csv('spotify_playlist_dataset2.csv')\n",
    "full_dataset_df = pd.concat([full_dataset_df1,full_dataset_df2], ignore_index=True)\n",
    "full_dataset_df.drop_duplicates(subset=['Track Name'], keep='first',inplace=True)\n",
    "print(full_dataset_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h0PZxMZM2Cd2",
   "metadata": {
    "id": "h0PZxMZM2Cd2"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "v8erhpD-L0xy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8erhpD-L0xy",
    "outputId": "e61b4f8f-9222-4c74-a27c-c423d27c1a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11794 entries, 0 to 17579\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        11794 non-null  int64  \n",
      " 1   Track Name        11793 non-null  object \n",
      " 2   Artist Name       11793 non-null  object \n",
      " 3   Popularity        11794 non-null  int64  \n",
      " 4   Release Year      11794 non-null  int64  \n",
      " 5   Explicit          11794 non-null  bool   \n",
      " 6   Danceability      11794 non-null  float64\n",
      " 7   Energy            11794 non-null  float64\n",
      " 8   Key               11794 non-null  int64  \n",
      " 9   Loudness          11794 non-null  float64\n",
      " 10  Mode              11794 non-null  int64  \n",
      " 11  Speechiness       11794 non-null  float64\n",
      " 12  Acousticness      11794 non-null  float64\n",
      " 13  Instrumentalness  11794 non-null  float64\n",
      " 14  Liveness          11794 non-null  float64\n",
      " 15  Valence           11794 non-null  float64\n",
      " 16  Tempo             11794 non-null  float64\n",
      " 17  Duration_ms       11794 non-null  int64  \n",
      " 18  Time Signature    11794 non-null  int64  \n",
      "dtypes: bool(1), float64(9), int64(7), object(2)\n",
      "memory usage: 1.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "Track Name          1\n",
       "Artist Name         1\n",
       "Popularity          0\n",
       "Release Year        0\n",
       "Explicit            0\n",
       "Danceability        0\n",
       "Energy              0\n",
       "Key                 0\n",
       "Loudness            0\n",
       "Mode                0\n",
       "Speechiness         0\n",
       "Acousticness        0\n",
       "Instrumentalness    0\n",
       "Liveness            0\n",
       "Valence             0\n",
       "Tempo               0\n",
       "Duration_ms         0\n",
       "Time Signature      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data in the playlist\n",
    "full_dataset_df.info()\n",
    "full_dataset_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JxlpWTgDJU-l",
   "metadata": {
    "id": "JxlpWTgDJU-l"
   },
   "source": [
    "As seen above, we still have some NaN values and an irrelevant column, we will now remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf8f774",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdf8f774",
    "outputId": "7805e00f-eaee-44ce-95a3-8c98f39c32d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11793 entries, 0 to 17579\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Track Name        11793 non-null  object \n",
      " 1   Artist Name       11793 non-null  object \n",
      " 2   Popularity        11793 non-null  int64  \n",
      " 3   Release Year      11793 non-null  int64  \n",
      " 4   Explicit          11793 non-null  bool   \n",
      " 5   Danceability      11793 non-null  float64\n",
      " 6   Energy            11793 non-null  float64\n",
      " 7   Key               11793 non-null  int64  \n",
      " 8   Loudness          11793 non-null  float64\n",
      " 9   Mode              11793 non-null  int64  \n",
      " 10  Speechiness       11793 non-null  float64\n",
      " 11  Acousticness      11793 non-null  float64\n",
      " 12  Instrumentalness  11793 non-null  float64\n",
      " 13  Liveness          11793 non-null  float64\n",
      " 14  Valence           11793 non-null  float64\n",
      " 15  Tempo             11793 non-null  float64\n",
      " 16  Duration_ms       11793 non-null  int64  \n",
      " 17  Time Signature    11793 non-null  int64  \n",
      "dtypes: bool(1), float64(9), int64(6), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Track Name          0\n",
       "Artist Name         0\n",
       "Popularity          0\n",
       "Release Year        0\n",
       "Explicit            0\n",
       "Danceability        0\n",
       "Energy              0\n",
       "Key                 0\n",
       "Loudness            0\n",
       "Mode                0\n",
       "Speechiness         0\n",
       "Acousticness        0\n",
       "Instrumentalness    0\n",
       "Liveness            0\n",
       "Valence             0\n",
       "Tempo               0\n",
       "Duration_ms         0\n",
       "Time Signature      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove irrelevant columns and drop any rows with NaN values\n",
    "full_dataset_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "full_dataset_df.dropna(inplace=True)\n",
    "full_dataset_df.info()\n",
    "full_dataset_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0MEBKI7DKLao",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MEBKI7DKLao",
    "outputId": "abdbfd43-d847-404d-9a92-e5782667c46c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Track Name', 'artists', 'popularity', 'release_year', 'explicit',\n",
       "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'duration_ms', 'time_signature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset_df = full_dataset_df.rename(columns={\"Acousticness\": \"acousticness\", \"Danceability\": \"danceability\",\"Energy\":\"energy\",\"Instrumentalness\":\"instrumentalness\",\"Liveness\":\"liveness\",\"Loudness\":\"loudness\",\"Popularity\":\"popularity\",\"Speechiness\":\"speechiness\",\"Tempo\":\"tempo\",\"Valence\":\"valence\",\"Duration_ms\":\"duration_ms\",\"Time Signature\":\"time_signature\",\"Key\":\"key\",\"Mode\":\"mode\", \"Artist Name\": \"artists\",\"Release Year\":\"release_year\",\"Explicit\":\"explicit\"})\n",
    "full_dataset_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n3caGewf2aOU",
   "metadata": {
    "id": "n3caGewf2aOU"
   },
   "source": [
    "## Data Preparation - Feature Engineering\n",
    "Firstly, we will be doing feature engineering, which will be the genre feature. As explained in the first notebook (Part 1: Genre Classification Model), We believe that this will be an essential feature in recommending tracks. We will be making use of the model and mapper from the Genre Classification Notebook to get this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b0f704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMultiLabelBinarizer:\n",
    "    def __init__(self):\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Fit the MultiLabelBinarizer to the data\n",
    "        self.mlb.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Transform the data, ignoring unseen labels\n",
    "        try:\n",
    "          return self.mlb.transform(X)\n",
    "        except ValueError as e:  \n",
    "          # Handle the case where the label set in X is not a subset of the label set fitted\n",
    "          unseen = set(x for sublist in X for x in sublist) - set(self.mlb.classes_)\n",
    "          X_filtered = [[x for x in sublist if x not in unseen] for sublist in X]\n",
    "          return self.mlb.transform(X_filtered)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Fit to data, then transform it\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        # Return feature names for output columns\n",
    "        return self.mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lCPzv4RxyijA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCPzv4RxyijA",
    "outputId": "57562a03-d35c-422e-fd65-443cb69af434"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syed_aliredha/anaconda3/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/syed_aliredha/anaconda3/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/syed_aliredha/anaconda3/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/syed_aliredha/anaconda3/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/syed_aliredha/anaconda3/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import pretrained models and mapper from other notebook\n",
    "with open('multinomial_logistic_regression_model.pkl', 'rb') as file:\n",
    "    multinomial_logistic_regression_model = pickle.load(file)\n",
    "with open('mapper.pkl', 'rb') as file:\n",
    "    mapper = pickle.load(file)\n",
    "\n",
    "# Function to extract the values from the DataFrames\n",
    "def get_genres(df):\n",
    "    df = df.copy()\n",
    "    df['artists'] = df['artists'].str.split(';')\n",
    "    df.drop(['Track Name', 'release_year','tempo','duration_ms'], axis=1, inplace=True)\n",
    "    X = mapper.transform(df)\n",
    "    X.columns = [col.replace('artists_', '').replace('[', '').replace(']', '').replace('<', '') for col in X.columns]\n",
    "    X = X.loc[:, ~X.columns.duplicated()]\n",
    "    genres = multinomial_logistic_regression_model.predict(X)\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "xZk_VbuYK9dk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZk_VbuYK9dk",
    "outputId": "4c1f20bf-9816-4028-ed52-d5efa367c818"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syed_aliredha/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['$uicideboy$', '*NSYNC', '+44', '112', '1999 WRITE THE FUTURE', '2 Chainz', '22 the Light', '2nd II None', '3k9x', '3slow2', '4 Non Blondes', '4batz', '6arelyhuman', '6ix9ine', '702', '730RARRI', '80purppp', '86Casino', '88rising', '8percent', '9infidell', 'A Boogie Wit da Hoodie', 'A Boy and His Kite', 'A Perfect Circle', 'A Tribe Called Quest', 'A!MS', 'A-Wall', 'ABBA', 'ADOY', 'AFROJACK', 'AGA', 'ALEXSUCKS', 'ALTÉGO', 'ALYA', 'ANTH', 'ASTN', 'ATARASHII GAKKO!', 'AVAION', 'Aaliyah', 'Aaron May', 'Aaron Smith', 'Aaron Tippin', 'Abby Anderson', 'Abe Parker', 'Abigail Bleu', 'Abigail Fierce', 'Abrina', 'Ace Hood', 'Ace of Base', 'Acoustic Vibe', 'Adam & The Ants', 'Adam Cashen', 'Adam Hicks', 'Adam Lambert', 'Adam Wheeler', 'Addy Lamaute', 'Adele', 'Adina Howard', 'Adrian Marcel', 'Adriano Spampanato', 'Afgan', 'Afroman', 'Agnes', 'Ahmad Jamal Trio', 'Ahzee', 'Aimee Carty', 'Air Supply', 'Alabama', 'Alana Springsteen', 'Albert Hammond Jr', 'Alejandro Sanz', 'Alek Olsen', 'Alemeda', 'Alesha Dixon', 'Alessandra', 'Alex & Sierra', 'Alex G', 'Alex Mica', 'Alex Parker', 'Alex Porat', 'Alex Turner', 'Alexander 23', 'Alexander Borodin', 'Alexander Oscar', 'Alexander Rybak', 'Alexander Scriabin', 'Alexandra Stan', 'Alice Coltrane', 'Alice DJ', 'Alice Merton', 'Alicks', 'Alina Baraz', 'All Mankind', 'All Saints', 'All-4-One', 'Allister', 'Allocai', 'Alpha Blondy', 'Alphonse Hasselmans', 'Altered Images', 'AlunaGeorge', 'Alvvays', 'Alx Veliz', 'Amanda Seyfried', 'American Authors', 'American Blonde', 'American Hi-Fi', 'Amerie', 'Aminé', 'Amy Grant', 'Amy Winehouse', 'Anamanaguchi', 'Anastacia', 'Anatoly Lyadov', 'Andrea Chahayed', 'Andrei Munteanu', 'Andrew Gialanella', 'Andrew Gordon', 'Andrew Huang', 'Andrew Neil and Code Purple', 'Andy Goodwin', 'Andy Rocks', 'Anella Herim', 'Angel Y Khriz', 'Angels & Airwaves', 'Angie Stone', \"Anita O'Day\", 'Anna Kendrick', 'Anna Naklab', 'Anonimo Anonimo', 'Anri', 'Ansel Elgort', 'Anthem Lights', 'Anthony Bonnette', 'Anthony Russo', 'Aqua', 'Aram Khachaturian', 'Arcade Fire', 'Arctic Monkeys', 'Arden Jones', 'Ari Abdul', 'Ari Lennox', 'Arizona Zervas', 'Arlo Parks', 'AronChupa', 'Arrested Development', 'Art Blakey', 'Art Blakey & The Jazz Messengers', 'Art Blakey Quintet', 'Art Farmer', 'Art Pepper', 'Art Tatum', 'Artemas', 'Arthur Conley', 'Artie Shaw', 'Artists Of Then, Now & Forever', 'Asaf Avidan', 'Ash', 'Ashanti', 'Ashlee Simpson', 'Ashley Alisha', 'Ashley Cooke', 'Ashley O', 'Aswad', 'At the Drive-In', 'Atlas Genius', 'Atlus', 'Atomic Kitten', 'Audio Push', 'Augustana', 'Austin George', 'Austin Snell', 'Austin Speed', 'Ava Della Pietra', 'Avant', 'Average White Band', 'Avril Lavigne', 'Ax and the Hatchetmen', 'Ayleen Valentine', 'Ayna Errboe', 'Ayo & Teo', 'Azealia Banks', 'B*Witched', 'B.E.R.', 'B2K', 'BACCDOE', 'BETWEEN FRIENDS', 'BICEP', 'BLITZ VEGA', 'BONES', 'BOYS LIKE GIRLS', 'BROCKHAMPTON', 'BROODS', 'Baauer', 'Baby Bash', 'Baby Keem', 'BabyJake', 'Babyshambles', 'Bad Bad Hats', 'Bad Company', 'Bad Meets Evil', 'Bad Suns', 'Bag Raiders', 'Baha Men', 'Bakar', 'Ball Greezy', 'Balu Brigada', 'Bambee', 'Bancali', 'Band Of Skulls', 'Band of Horses', 'Banda AL9', 'Bando Jonez', 'Banes World', 'Bankrol Hayden', 'Bantu', 'Barbra Streisand', 'Barenaked Ladies', 'Barry Manilow', 'Barry White', 'Baseball Gregg', 'Basshunter', 'Bat For Lashes', 'Bathe Alone', 'Beach Weather', 'Bear Hands', 'Bear Mountain', 'Beastie Boys', 'Bedřich Smetana', 'Bee Gees', 'Beenie Man', 'Beirut', 'Belanova', 'Beldon Haigh', 'Bell Biv DeVoe', 'Belly', 'Ben Howard', 'Ben Lawrence', 'Ben McPeak', 'Ben Webster', 'Benny Goodman Quartet', 'Benny Goodman Sextet', 'Benny Goodman Trio', 'Benson Boone', 'BertieBanz', 'Best Not Broken', 'Bette Midler', 'Betty Carter', 'Betty Wright', 'Beware Of Darkness', 'Bic Runga', 'Biffy Clyro', 'Big Boss Vette', 'Big Brovaz', 'Big Data', 'Big Pun', 'Big Thief', 'Big Time Rush', 'Big Tymers', 'BigXthaPlug', 'Bill Charlap', 'Bill Evans Trio', 'Bill Lovelady', 'Bill Medley', 'Billie Jo Jones', 'Billie Joe Armstrong', 'Billy Ocean', 'Bingo Players', 'Binocular', 'Birdman', 'Biz Markie', 'Bizarrap', 'Black Coast', 'Black Kids', 'Blackstreet', 'Blaine', 'Blake Roman', 'Blame My Youth', 'Blanks', 'Bloc Party', 'BlocBoy JB', 'Blondes', 'Blondfire', 'Blondshell', 'Blood Circus', 'Blood Orange', 'Bloodstone', 'Blossoms', 'Blu Cantrell', 'Blu DeTiger', 'Blue', 'Blue Foundation', 'Blue Magic', 'Blue Swede', 'Blueface', 'Blush', 'Bo Burnham', 'Bob Sinclair', 'Bob Sinclar', 'Bobby \"Boris\" Pickett & The Crypt-Kickers', 'Bobby Caldwell', 'Bobby Shmurda', 'Bobby V.', 'Bobby Womack', \"Bomfunk MC's\", 'Bone Thugs-N-Harmony', 'Bonnie Tyler', 'Booba', 'Boosie Badazz', 'Bow Wow', 'Bowling For Soup', 'Box Car Racer', 'Boy Meets Girl', 'Brad stank', 'Braden Bales', 'Brandon Beal', 'Brandon Flowers', 'Brandy', 'Breakbot', 'Breaking Beattz', 'Breakup Shoes', 'Brenn!', 'Brent Faiyaz', 'Bridgit Mendler', 'Brighid Nora', 'Bright Eyes', 'Brittany Howard', 'Brock Davis', 'Broken Bells', 'Brooks Jefferson', 'Bros', 'Bros Project', 'Brother Dege', 'Brothers Osborne', 'Bruce Hornsby', 'Bruno Major', 'Bryan Martin', 'Brye', 'Bubba Sparxxx', 'Bubble Tea and Cigarettes', 'Buck Owens', 'Bucks Fizz', 'Bud Powell', 'Budman.', 'Bull Beats', 'Bully', 'Butter Bath', 'Bvtter', 'BØRNS', 'C & C Music Factory', 'C.W. McCall', 'CAKE', 'CARR', 'CHIC', 'CHIKA', 'CJ', 'CKay', 'CORBAL', 'Caesars', 'Cal Scruby', 'Calboy', 'Caleb Shirley', 'Cali Dubs', 'Cali Swag District', 'Cam', 'Cam Allen', \"Cam'ron\", 'CamelPhat', 'Cameo', 'Camera Obscura', 'Camp Lo', 'Canaan Smith', 'Candi Staton', 'Cannons', 'Captain & Tennille', 'Caramella Girls', 'Carine', 'Carl Douglas', 'Carl Pedida', 'Carla Bruni', 'Carly Simon', 'Carmen McRae', 'Carnage', 'Carole King', 'Carolina Liar', 'Caroline Polachek', 'Carrie Frey', 'Carrie Q', 'Cartel De Santa', 'Case', 'Cashmere Cat', 'Cass Elliot', 'Cassidy', 'Cassie', 'Cassyette', 'Cast - Liv and Maddie', 'Cat Burns', 'Cat Janice', 'Catfish and the Bottlemen', 'Cbarrgs', 'Celeste', 'Central Cee', 'Chaka Demus & Pliers', 'Chaka Khan', 'Chamillionaire', 'Champaign', 'Chantel Jeffries', 'Chappell Roan', 'Charles & Eddie', 'Charles Aznavour', 'Charles Dillinger', 'Charles Mingus', 'Charles Wesley Godwin', 'Charles Wright & The Watts 103rd Street Rhythm Band', 'Charley Pride', 'Charlie Argo', 'Charlie Parker', 'Charlie Parker Quartet', 'Charlie Rich', 'Charlotte Sands', 'Chase Atlantic', 'Chase Matthew', 'Chase McDaniel', 'Chase Rice', 'Chayanne', 'Chayce Beckham', 'Cheb Mami', 'Cher', 'Cherish', 'Cherub', 'Cheryl', 'Cheryl Lynn', 'Ches Anthony', 'Chet Faker', 'Chevelle', 'Chick Corea', 'Chico Rose', 'Chiddy Bang', 'Chief Keef', 'Childish Gambino', 'China Anne McClain', 'Chingy', 'Chip', 'Chloe x Halle', 'Chloë Doucet', 'Chris Burton', 'Chris Cagle', 'Chris Coco', 'Chris Isaak', 'Chris Lake', 'Chris Renzema', 'Chris Young', 'Christina Milian', 'Christine Baranski', 'Chromeo', 'Chronyx', 'Chumbawamba', 'Churchill', 'Ciara', 'Cider Sky', 'Cir.Cuz', 'Circa Waves', 'City Girls', 'City and Colour', 'Clams Casino', 'Classified', 'Cleo Sol', 'Clint Black', 'Clipse', 'Coast Modern', 'Coasts', 'Cochise', 'Coco Jones', 'Coconut Records', 'Cody Jinks', 'Coi Leray', 'Colbie Caillat', 'Coldcut', 'Cole Phillips', 'Coleman Hawkins', 'Coleman Hawkins Quartet', 'Collin Raye', 'Colony House', 'Colter Wall', 'Commodores', 'Confederate Railroad', 'Connor Ashnault', 'Connor Price', 'Conor Burns', 'Conor Ross', 'Conway Twitty', 'Corb Lund', 'Corey Kent', 'Corey Wise', 'Cornershop', 'Corona', 'Cory Wong', 'Courteeners', 'Coyote Forest', 'Coyote Theory', 'Craig David', 'Craig Mack', 'Craig Morgan', 'Crash Test Dummies', 'Crisaunt', 'Crispy脆樂團', 'Crowded House', 'Crumb', 'Crying 4 Kafka', 'Crystal Fighters', 'Crystal Gayle', 'Crystal Waters', 'Cub Scouts', 'Cuco', 'Current Joys', 'Cut Copy', 'Cyndi Lauper', 'Cyril Scott', 'Czech Symphony Chamber Group', 'César Franck', \"D'Angelo\", 'D. Fagan', 'D12', 'D4L', 'DAP The Contract', 'DDG', 'DESTIN CONRAD', 'DIRTYXAN', 'DJ Antoine', 'DJ Comento', 'DJ Jazzy Jeff & The Fresh Prince', 'DJ Karim', 'DJ Khaled', 'DJ Paul', 'DJ Rapture', 'DLU Kemp', 'DMX', 'DNA', 'DON BROCO', 'DOPE LEMON', 'DPR IAN', 'DRAM', 'DRAMA', 'DVBBS', 'DVRST', 'DWLLRS', 'DXSTINY', 'Dagny', 'Daisy Jones & The Six', 'Dalton Davis', 'Dan Bull', 'Dane Amar', 'Daniel Adams-Ray', 'Daniel Powter', 'Danity Kane', 'Danzig', 'Darell', 'Darondo', 'Dasha', 'Daughter', 'Dave', 'Dave Holland Quartet', 'Dave Hollister', 'David Allan Coe', 'David Lee Murphy', 'David Morris', 'David Nail', 'David Rosales', 'David Shire', 'David Starr', 'Day Wave', 'Daya Shanelle', 'Dayglow', 'Dazel Ukuto', 'Ddark', 'De La Soul', 'DeJ Loaf', 'Deacon Blue', 'Deaf Dreamer', 'Deaf Havana', 'Deana Carter', 'December 3rd', 'Dee C. Lee', 'Deee-Lite', 'Deep Blue Something', 'Dehd', 'Del The Funky Homosapien', 'Del Water Gap', 'Delacey', 'Delegation', 'Dem Franchize Boyz', 'Deniece Williams', 'Denise Julia', 'Dennis Lloyd', 'Denzel Curry', 'Depeche Mode', 'Dept', 'Derek Jones', 'Deribb', 'Desiigner', \"Destiny's Child\", 'Destroy Boys', 'Devin Kennedy', 'Dexter Gordon', 'Dexys Midnight Runners', 'Dhruv', 'Diamond Rio', 'Diana Krall', 'Diana Ross', 'Diddy', 'Die Antwoord', 'Digable Planets', 'Digital Underground', 'Digitalism', 'Dimitri Vangelis & Wyman', 'Dionne Warwick', 'Dirty Pretty Things', 'Dirty Vegas', 'DirtyGloveCJay', 'Discovery', 'Distorted Resonance', 'Divinyls', 'Dizzy Gillespie', 'Dj Laz', 'Django Reinhardt', 'Djo', 'Doc Gynéco', 'Docksuns', 'Domenico Scarlatti', 'Donavon Frankenreiter', 'Donell Jones', 'Donna Lewis', 'Donna Summer', 'Dot Viera', 'Dove Cameron', 'Dr. Dog', \"Dre'es\", 'Dream Easy Collective', 'Dreamer Boy', \"Dreams We've Had\", 'Dreamville', 'Drew Holcomb', 'Driftless Pony Club', 'Dry the River', 'Duck Sauce', 'Duffy', 'Duke Ellington & His Washingtonians', 'Duncan Sheik', 'Duo Multicorde', 'Dustin Lynch', 'Dwight Yoakam', 'Dylan Conrique', 'Dylan Gossett', 'Dylan Marlowe', 'Dylan Mckaige', 'Dylan Scott', 'Dyland & Lenny', 'Dzeko & Torres', 'EKKSTACY', 'ELYAZ', 'Eagle-Eye Cherry', 'Eamon', 'Earl Hines', 'Earlay', 'Earth, Wind & Fire', 'Earthquake Lights', 'Eastern Thrills', 'Easton Corbin', 'Ed Sheeran & Justin Bieber', 'Eddie Floyd', 'Eddie Murphy', 'Eddie Zuko', 'Edine', 'Edison Lighthouse', 'Editors', 'Edward Elgar', 'Edwin McCain', 'Eek-A-Mouse', 'Egg', 'Eiffel 65', 'Eisley', 'El Chevo', 'Elan Noon', 'Electric Guest', 'Electric Light Orchestra', 'Elephant Castle', 'Elias Boussnina', 'Elina', 'Elise Trouw', 'Eliza Doolittle', 'Eliza Rose', 'Elizabeth', 'Ella Langley', 'Ella Mai', 'Ellery Bonham', 'Elvis Crespo', 'Emblem3', 'Emilia', 'Emily Burns', 'Emotional Oranges', 'Empire Of The Sun', 'Empress Latoyah', 'Empress Of', 'Enrique Granados', 'Enrique Iglesias', 'Enur feat. Natasja', 'Eric B. & Rakim', 'Eric Bellinger', 'Eric Bolton', 'Eric Carmen', 'Erik Frank', 'Erin Kinsey', 'Ernest Bloch', 'Erykah Badu', 'Esbjörn Svensson Trio', 'Esperanza Spalding', 'Eugene Wilde', 'Evan Honer', 'Eve', 'Evelyn \"Champagne\" King', 'Everlong', 'Everything Everything', 'Example', 'Eyedress', 'Ezra Williams', 'F.L.Y. (Fast Life Yungstaz)', 'FIFTY FIFTY', 'FORTELLA', 'FRONTEERS', 'FYI the Rapper', 'Fabian Secon', 'Fabolous', 'Fake Laugh', 'Falco', 'Familiar Faces', 'Family of the Year', 'Famous Dex', 'Fanfarlo', 'Far Corporation', \"Fat Freddy's Drop\", 'Fat Joe', 'Fatboy Slim', 'Father John Misty', 'Fatman Scoop', 'Faul & Wad', 'Faye Webster', 'Fedde Le Grand', 'Feeder', 'Fefe Dobson', 'Feist', 'Felix Godefroid', 'Feng Suave', 'Ferly Jay', 'Fernando Furones', 'Fetty Wap', 'Feyesal', 'Fiction Factory', 'Fiji Blue', 'Fin Argus', 'Finatticz', 'Finding Hope', 'Fireboy DML', 'Five', 'Five Finger Death Punch', 'Five Star', 'Flamingos in the Tree', 'Flanør', 'Fleet Foxes', 'Flight', 'Flight Facilities', 'Flipp Dinero', 'Flo Milli', 'Florence Beatrice Price', 'FloyyMenor', 'Flume', 'Fontaines D.C.', 'Fools Garden', 'Forest Blakk', 'Forever The Sickest Kids', 'Forrest Frank', 'Foster', 'Four Tops', 'Fox Academy', 'Foxwarren', 'Foxy Brown', 'Francis Poulenc', 'Francisco Tárrega', 'Frank Sinatra', 'Frankee', 'Frankie Valli', 'Freaks & Geeks', 'Fred again..', 'Freddie Hubbard', 'Frederick Delius', 'Freedom Dub', 'Freestyle', 'Freya Ridings', 'Friday Pilots Club', 'Fridayy', 'Fritz Kreisler', 'Frizk', 'Fruit Bats', 'Fugees', 'Fujii Kaze', 'Full Tone Generator', 'Fuller', 'Fun Guns', 'Funeral Suits', 'Funkadelic', 'Future Animals', 'Future Mondays', 'G-Unit', 'G.R.L.', 'GABRIELLE', 'GAWNE', 'GEMINI', 'GRAHAM', 'GROUPLOVE', 'GXTP', 'Gabi Sklar', 'Gabrielle', 'Gabriels', 'Gallant', 'Galt MacDermot', 'Gang Starr', 'Garbage', 'Gareth.T', 'Garry DW Judd', 'Garth Brooks', 'Gary Allan', 'Gary Burton', 'Gary Glitter', 'Gary Kyle', 'Gary Wayne', 'Gavin Adcock', 'Gavin DeGraw', 'Gavin Porsche', 'Gene Ammons', 'Generationals', 'Genesis', 'Genevieve Stokes', 'Gente De Zona', 'George Baker Selection', 'George Benson', 'George Jones', 'George McCrae', 'George Michael', 'George Shearing Quintet', 'Georgia Webster', 'Geowulf', 'Geri Halliwell', 'Germaine Tailleferre', 'Gerreddi', 'Gerry & The Pacemakers', 'Gerry Mulligan', 'Gerry Mulligan & Johnny Hodges', 'Gerry Mulligan Quartet', 'Geto Boys', 'Ghost Town DJs', 'Ghostemane', 'Gian Marco Castro', 'Giant Rooks', \"Gigi D'Agostino\", \"Gilbert O'Sullivan\", 'Ginger Root', 'Giordana Angi', 'Gipsy Kings', 'Girlicious', 'Gladys Knight & The Pips', 'Glass Caves', 'Glasvegas', 'Glee Cast', 'Glenn Miller', 'Glisha', 'Glitter Dream', 'Glitter Party', 'Glom', 'Gloria Estefan And Miami Sound Machine', 'Gloria Gaynor', 'Gold', 'Gold Fields', 'Gold Motel', 'Goldfinger', 'Good Kid', 'Good Neighbours', 'Good Times Ahead', 'Gossip', 'Gotye', 'Grabbitz', 'Grace Carter', 'Grandmaster', 'Granger Smith', 'Grant Green', 'Grass', 'Green River', 'Gregory Abbott', 'Gregory Isaacs', 'Gretchen Wilson', 'Griffin Williams', 'Grizzly Bear', 'Gruntruck', 'Guru', 'Guru Josh Project', 'Gus Dapperton', 'Gusttavo Lima', 'Gutter Grinders', 'Gypsy Goode', 'Gyptian', 'H.E.R.', 'HAARPER', 'HAIM', 'HIGHWAYVES', 'HIIT BPM', 'HOLLY MONROE', 'HONNE', 'HYBS', 'Haddaway', 'Haiden Henderson', 'Hail Caesar', 'Hail Rell', 'Hailee Steinfeld', 'Hal Ketchum', 'Handsome Boy Modeling School', 'Hank Mobley', 'Hank Williams, Jr.', 'Hannah Montana', 'Hannah Noel', 'Hans.', 'Hanson', 'Happy Mondays', 'Hard Lights', 'Hard-FI', 'Harmless', 'Harrison Boe', 'Harry Belafonte', 'Harry Chapin', 'Harry Connick, Jr.', 'Harvey Danger', 'He Is We', 'Headie One', 'Heavy D & The Boyz', 'Heidi Montag', 'Heitor Villa-Lobos', 'Hellogoodbye', 'Henrik', 'Henry Moodie', 'Henry Morris', 'Hentai Xander', \"Her's\", 'Hermitude', 'High Highs', 'High Mountain Breezes', 'High School Musical Cast', 'High Tyde', 'Highway Outlaws', 'Hiko', 'Hilltop Hoods', 'Hippie Sabotage', 'Hippo Campus', 'Hippo Dreams', 'Hojean', 'Home', 'Homson', 'Horace Brown', 'Horace Silver', 'Horsebeach', 'Hosemen', 'Hot Chocolate', 'Hot Hot Heat', 'Hot Mulligan', 'Hot for Crime', 'Hotel Ugly', 'Houston', 'Hov1', 'How We Burn', 'Hues Corporation', 'Huey Lewis & The News', 'Huncho Jack', 'Hundred Stacks', 'Hurricane Chris', 'Hypaton', 'Héctor \"El Father\"', 'ILLIT', 'INDIANS', 'Ian Carey Project', 'Ian Dury', 'Ice Spice', 'Ida Corr', 'Idina Menzel', 'Iggy Azalea', 'Iko', 'Illatek', 'Imperial Mammoth', 'In The Valley Below', 'India Lake', 'India.Arie', 'Indigo Girls', 'Indila', 'Infinity Song', 'Inhaler', 'Inspiral Carpets', 'Internet Money', 'Interpol', 'Irene Cara', 'Isaac Albéniz', 'Isabel LaRosa', 'Isac Elliot', 'Isla-Maria', \"Israel Kamakawiwo'ole\", 'ItaloBrothers', 'J Boog', 'J Roofless', 'J Spades', 'J-Kwon', 'J. Holiday', 'J. Maya', 'J.Lauryn', 'JACKBOYS', 'JANNABI', 'JEANZ', 'JHIN', 'JLS', 'JNR CHOI', 'JON VINYL', 'JORDANN', 'JP Saxe', 'JR JR', 'JT Music', 'JUST INCASE', 'JUVENILE', 'JW', 'JW Velly', 'Ja Rule', 'Jace Everett', 'Jack Back', 'Jack Johnson', 'Jack Kays', \"Jack Stauber's Micropop\", 'Jacki Thrapp', 'Jackie McLean', 'Jacob Collier', 'Jacob Tillberg', 'Jacquees', 'Jada', 'Jada Facer', 'Jade Bird', 'Jade LeMac', 'Jaden', 'Jagged Edge', 'Jagguar', 'Jaheim', 'Jain', 'Jake Banfield', 'Jake Bugg', 'Jakob', 'Jakob Karlberg', 'Jalen Ngonda', 'Jalen Santoy', 'Jamelia', 'James', 'James Blake', 'James Morrison', 'James Otto', 'James Smith', 'James Vincent McMorrow', 'Jamey Johnson', 'Jamie Cullum', 'Jamie Foxx', 'Jamie T', 'Jamiroquai', 'Jan Johansson', 'Jan Metternich', 'Jana Kramer', 'Jane Bell', 'Jane Krakowski', 'Janet Jackson', 'Japan', 'Jason Chen', \"Javi That's Me\", 'Jay Rock', 'Jay.f.k beats', 'JayDaYoungan', 'JayWolf', 'Jaymay', 'Jayme Dee', 'Jazz Cartier', 'Jazzinuf', 'Jealous Friend', 'Jean Dawson', 'Jeanne & The Darlings', 'Jeff Bernat', 'Jelani Aryeh', 'Jelly Roll', 'Jenna Raine', 'Jennifer Hudson', 'Jennifer Rush', 'Jenny Tolman', 'Jeremy Passion', 'Jermaine Stewart', 'Jerrod Niemann', 'Jerry Cantrell', 'Jesse Barrera', 'Jesse McCartney', 'Jessica Mauboy', 'Jessie J', 'Jessie Murph', 'Jet Fuel & Ginger Ales', 'Jez Dior', 'Jhana Boy', 'Jimmie Allen', 'Jimmy Smith', 'Jo Boxers', 'Jo Dee Messina', 'JoJo', 'Joe', 'Joe Ciotti', 'Joe Diffie', 'Joe Gillette', 'Joe Henderson', 'Joe Lovano', 'Joe Nichols', 'Joe P', 'Joe Pass', 'Joey Bada$$', 'Johann Strauss II', 'John Anderson', 'John Coltrane Quartet', 'John Farnham', 'John Holt', 'John Mellencamp', 'John Travolta', 'Johnny Gill', 'Johnny Goth', 'Johnny Griffin', 'Johnny Hodges', 'Johnny Hodges & His Orchestra', 'Johnny Logan', 'Johnny Nash', 'Johnny Paycheck', 'Johnny Stimson', 'Joji', 'Jonas Hoffmann', 'Jonathan Boulet', 'Jontae', 'Jordan Dean', 'Jordan Ward', 'Jordin Sparks', 'Joseph Boulogne Chevalier de Saint-Georges', 'Josh Gibbs', 'Josh Gracin', 'Josh Levi', 'Josh Meloy', 'Josh Ross', 'Joy Again', 'Joytastic Sarah', 'Joywave', 'Judah & the Lion', 'Juelz Santana', 'Julia Alexa', 'Julia Cole', 'Julia Jacklin', 'Juliet Ivy', 'Julián Fueyo', 'July Talk', 'Jungle', 'Junior Jack', 'Junior M.A.F.I.A.', 'Junior Senior', 'Just Jack', 'Justice', 'Justin Champagne', 'Justina Valentine', 'Jutta Hipp', 'J€AN-MARC', 'KAIRO', 'KC & The Sunshine Band', 'KDA', 'KG Floss', 'KIIINGSAM', 'KIRBY', 'KONGOS', 'KRS-One', 'Kaash Paige', 'Kaden MacKay', 'Kadri Williams', 'Kamal.', 'Kameron Marlowe', 'Kandi', 'Kansas', 'Kardinal Offishall', 'Karen O', 'Karen Souza', 'Karim', 'Karmin', 'Kasabian', 'Kat Deluna', 'Kate Nash', 'Katrina & The Waves', 'Kauai45', 'Kaylee Bell', 'Keanu Bicol', 'Keith & Tex', 'Keith Anderson', 'Keith Jarrett', 'Keith Whitley', 'Keke Palmer', 'Kelis', 'Kellie Pickler', 'Kelly Clarkson', 'Kelsey Hart', 'Kenneth Koultre', 'Kenny Burrell', 'Kenny Dorham', 'Kenny Loggins', 'Kenny Mason', 'Kenny Wayne Shepherd', 'Kenya Grace', 'Keri Hilson', 'Kermit', 'Kevin Abstract', 'Kevin Gates', 'Kevin Lyttle', 'Kevin Rudolf', 'Kevin Teasley', 'Khaled', 'Khia', 'Khruangbin', 'Kid Sistr', 'Kid Travis', 'Kids That Fly', 'Kiesza', 'Kiko', 'Kiko Bun', 'Kim Carnes', 'Kim Wilde', 'Kina', 'King Curtis', 'King Princess', 'King Von', 'Kings of Leon', 'Kinneret', 'Kinny', 'Kitten', 'Kitty Wells', 'Klangkarussell', 'Klawuta', 'Klaxons', 'Klingande', 'KnowKnow', 'Knox', 'Kobe Fresh outta High School', 'Koi', 'Kokoroko', 'Kool & The Gang', 'Kris Kross', 'Kristinia DeBarge', 'Krooked Kings', 'Ktlyn', 'Ku$h Drifter', 'Kula Shaker', 'Kurosuke', 'Kuwada', 'Kxllswxtch', 'Kxlly', 'Kyle Hume', 'L. Martin', 'LANCO', 'LEN', 'LL COOL J', 'LP', 'LUCKI', 'LXNGVX', 'La La La La', 'Labi Siffre', 'Lady Danville', 'Ladyhawke', 'Laid Back', 'Lainey Wilson', 'Landon Austin', 'Larry Fleet', 'Larry Young', 'Lars Gullin', 'Las Ketchup', 'Last Dinosaurs', 'Last of the 80s', 'Lay Bankz', 'Layzi', 'Leah Kate', 'Leah Marie Perez', 'Leanna Firestone', 'Lee Ann Womack', 'Lee Brice', 'Lee Konitz', 'Lee Morgan', 'Legarda', 'Lemar', 'Lennon Cripe', 'Leo Brouwer', 'Leo Raposão', 'Leon Thomas', 'Leona Lewis', 'Leoš Janáček', 'Leroy Hutson', 'Lesley Gore', 'Letdown.', 'Letters To Cleo', 'Levon Forever', 'Lewis Capaldi', 'Lewis Watson', 'Lexi Jayde', 'Liam Gallagher', 'Liberty X', 'Libianca', 'Lift The Curse', 'Lil Dicky', 'Lil Jon & The East Side Boyz', 'Lil Mabu', 'Lil Mama', 'Lil Mosey', 'Lil Pump', 'Lil Skies', 'Lil Tecca', 'Lil Xan', 'Lil Yachty', 'Lili Boulanger', 'Lilithzplug', 'Lilly Wood and The Prick', 'Lime Cordiale', 'Linda Jones', 'Lionel Hampton', 'Lionel Richie', 'Lipa DJ', 'Lipps Inc.', 'Lisa Loeb', 'Lissie', 'Lit', 'Litany', 'Little Green Cars', 'Lizzy McAlpine', 'Lloyd', 'Lloyd Banks', 'Local Natives', 'Lofty', 'Logan Ledger', 'Logan Paul', 'Lojay', 'Lola Young', 'Lonely God', 'Lonr.', 'Looking Glass', 'Loona', 'Loopey', 'Lorde', 'Loreen', 'Lorez Alexandria', 'Lorn', 'Los Campesinos!', 'Lost Kings', 'Lou Bega', 'Lou Donaldson', 'Lou Reed', 'Louis Armstrong & His Hot Five', 'Louis Armstrong & His Savoy Ballroom Five', 'Louis Tomlinson', 'Love Battery', 'Love Spells', 'Lovejoy', 'Loverboy', 'Lovey', 'Lucaa', 'Lucy Pearl', 'Luigi Boccherini', 'Luis Fonsi', 'Luke Chiang', 'Luke Hemmings', 'Lumidee', 'Luna Bay', 'Luna Waves', 'Lunar Vacation', 'LunchMoney Lewis', 'Luny Tunes', 'Lupe Fiasco', 'Luther Vandross', 'LuxFlowz', 'Luísa Sonza', 'Lydell Lucky', 'Lydia', 'Lyfe Jennings', 'Lynn Anderson', 'M.A.G.S.', 'M.O.P.', 'M83', 'MARVIN', 'MASN', 'MC Eiht', 'MC Hammer', 'MEG MYERS', 'MF DOOM', 'MFSB', 'MIKA', 'MINOVA', 'MIRA', 'MK', 'MODSi', 'MONA', 'MUNA', 'Mac Ayres', 'Mac Lethal', 'Mac NL', 'MacKenzie Porter', 'Mackenzie Testa', 'Macklemore & Ryan Lewis', 'Madcon', 'Madd Hatter', 'Maddie Poppe', 'Made Violent', 'MadeinTYO', 'Madilyn Mei', 'Madness', 'Mae Stephens', 'Maeta', 'Maggie Lindemann', 'Maggie Rogers', 'Magic System', 'Maitchhh', 'Majek Fashek', 'Mak Daddy Revue', 'Makaveli', 'Mal Waldron', 'Malcolm Todd', 'Malfunkshun', 'Manchester Orchestra', 'Mandy Moore', 'Manfred Mann', \"Manfred Mann's Earth Band\", 'Manic Street Preachers', 'Mann', 'Manu Chao', 'Manuel de Falla', 'Marc Berger', 'Marc Cohn', 'Marcello Rosciglione', 'Marcus & Martinus', 'Marcus King', 'Marcy Playground', 'Mareux', 'Margrels', 'Mariah Carey', 'Mariah the Scientist', 'Mario', 'Mariposa', 'Mark Ambor', 'Mark Chesnutt', 'Mark Knopfler', 'Mark Morrison', 'Mark Wills', 'Marlena Shaw', 'Martha Reeves & The Vandellas', 'Martika', 'Martin Solveig', 'Martina McBride', 'Marty Robbins', 'Mary Lou Williams', 'Mary Mary', 'Maryon', 'Masego', 'Mason', 'Mason Ramsey', 'Massari', 'Matt', 'Matt DiMona', 'Matt Hires', 'Matt Stell', 'Matt Wertz', 'Matt and Kim', 'Mattafix', 'Matthew Wilder', 'Max Romeo', 'Maximo Diego Pujol', 'Maximo Park', 'Maxwell', 'McFly', 'Me Like Bees', 'Me and My Sandcastle', 'Me.man.machine', 'Meat Loaf', 'Medina', 'Medium Build', 'Meek Mill', 'Meet Me @ The Altar', 'Megumi Acorda', 'Mel McDaniel', \"Meli'sa Morgan\", 'Mellow Fellow', 'Melo Griffith', 'Melo-D', 'Melvins', 'Men At Work', 'Men Without Hats', 'Meredith Brooks', 'Merle Haggard', 'Merle Haggard & The Strangers', 'Meryl Streep', 'Method Man', 'Metric', 'Metro Station', 'Metronomy', 'Mia Maestro', 'Miami Sound Machine', 'Michael Bolton', 'Michael Constantino', 'Michael Franti & Spearhead', 'Michael Gray', 'Michael Kiwanuka', 'Michael Marcagi', 'Michael Mayo', 'Michael Sanderson', 'Michael Schulte', 'Michael Sembello', 'Michael Seyer', 'Michel Teló', 'Michelle Branch', 'Michelle Williams', 'Microwave', 'Middle Child', 'Midi Monstaz', 'Midnight Oil', 'Migos', 'Miguel', 'Miguel Llobet Solés', 'Mike G', 'Mike Jones', 'Mike WiLL Made-It', 'Mikhail Glinka', 'Mikky Ekko', 'Mild High Club', 'Miles Davis Quintet', 'Miles Gaston Villanueva', 'Miles Kane', 'Militarie Gun', 'Milky Chance', 'Milky Day', 'Millencolin', 'Miller Holler', 'Milli Vanilli', 'Millionyoung', 'Milo Gore', 'Milt Jackson', 'Miniature Tigers', 'Mint Condition', 'Miracle Musical', 'Miranda Cosgrove', 'Mirla Avila', 'Mis-Teeq', 'Missy Elliott', 'Mitch Rowland', 'Mobb Deep', 'Moderat', 'Modest Mouse', 'Modjo', 'Moe Everything', 'Mokita', 'Monica', 'Monrroe', 'Mont Duamel', 'Montell Fish', 'Montell Jordan', 'Montgomery Gentry', 'Moon Fever', 'Moon Taxi', 'Moon Walker', 'Morning Runner', 'Morrissey', 'Morten Lauridsen', 'Motion City Soundtrack', 'Mr Little Jeans', 'Mr.Kitty', 'Ms. Lauryn Hill', 'Mudhoney', \"Mungo's Hi Fi\", 'Munn', 'Muscadine Bloodline', 'Muse', 'Musical Youth', 'My Chemical Romance', 'MyKey', 'Mystery Jets', 'Mystery Skulls', 'Mystikal', 'Måns Zelmerlöw', 'Ménélik', 'N-Dubz', 'N.E.R.D', 'N.O.R.E.', 'N.W.A.', 'NATTI NATASHA', 'NAV', 'NIKI', 'NLE Choppa', 'NONONO', 'Nacho', 'Naomi Prie', 'Naomi Scott', 'Nappy Roots', 'Nardo Wick', 'Nas', 'Nat & Alex Wolff', 'Natalie Imbruglia', 'Natalie La Rose', 'Nate Bryan', 'Nate Feuerstein', 'Nate Smith', 'Nathan Evans', 'Nathan Morris', 'Nation Band NY', 'Nation of Language', 'Natiruts', 'Naturally 7', 'Naughty Boy', 'Naughty By Nature', 'Nayer', 'Nebu Kiniza', 'Nelly', 'Nelly Furtado', 'Nena', 'Nep', 'Nessbeal', 'Neutral Milk Hotel', 'Nevada', 'Never Get Used To People', 'New Edition', 'New Found Glory', 'New Kids On The Block', 'New Radicals', 'NewJeans', 'Nic D', 'Nick Jonas', 'Nick Leng', 'Nicky Youre', 'Nico & Vinz', 'Nicole Scherzinger', 'Night Cap', 'Nightcore Remix Guys', 'Nightmares On Wax', 'Nikka Costa', 'Niko B', 'Niko Walters', 'Nikolai Rimsky-Korsakov', 'Nine Days', 'Nine Inch Nails', 'Nipsey Hussle', 'Nitty Gritty Dirt Band', 'Nivea', 'Niykee Heaton', 'No Hot Ashes', 'No Vacation', 'Noah Crisostomo', 'Noah Floersch', \"Noel Gallagher's High Flying Birds\", 'Noisestorm', 'Noisettes', 'Norman Greenbaum', 'Normani', 'Nothing But Thieves', 'NovaVerse', 'Now, Now', 'O-Zone', 'O.A.R.', 'O.T. Genasis', 'ODESZA', 'OHGEESY', 'OK Go', 'OMC', 'OMI', 'OMMIEH', 'ONE OK ROCK', 'OPEN HOUSE', 'OPM', 'Oberhofer', 'Ocean Alley', 'Ocean Colour Scene', 'Odd Future', 'Odyssey', 'Ogi', 'Ohio Players', \"Ol' Rattlebones\", 'Old Dominion', 'Ole 60', 'Oliver Anthony Music', 'Olivia Newton-John', 'Ollie MN', 'Olly Alexander (Years & Years)', 'Olly Murs', 'Omah Lay', 'Omarion', 'One-T', 'Onyx', 'Oobie', 'Orianthi', 'Ornette Coleman', 'Orson', 'Oscar Peterson Trio', 'Otto Knows', 'Outkast', 'Outlandish', 'Owen Paul', 'Owen Riegling', 'Oxlade', 'Ozs', 'PANDIT', 'PARIS The Prince', 'PLVTINUM', 'POP ETC', 'PVRIS', 'Pacific Avenue', 'Paolo Nutini', 'Paradiso Girls', 'Paramore', 'Parcels', 'Paris Hilton', 'Parliament', 'Parmalee', 'Pat Benatar', 'Patience & Prudence', 'Patsy Cline', 'Patty Smyth', 'Paul Blanco', 'Paul Damixie', 'Paul Desmond', 'Paul Kalkbrenner', 'Paul McDonald', 'Paul Russell', 'Paul Weller', 'Paula Abdul', 'Paula Cole', 'Pauline Zoe Park', 'Pavement', 'Peace', 'Peace Cult', 'Peach Luffe', 'Peach Pit', 'Peach Tree Rascals', 'Peachy!', 'Pebbles', 'Peggy Gou', 'Pete Rock', 'Pete Rock & C.L. Smooth', 'Peter Gabriel', 'Peter McPoland', 'Petey Pablo', 'Petra Marklund', 'Pham', 'Phantom Planet', 'Phil Collins', 'Phil Oakey', 'Phil Vassar', 'Phil Woods', 'Philip Bailey', 'Philip George', 'Phoenix', 'Phony Ppl', 'Phora', 'Pia Mia', 'Picture Day', 'Piff Marti', 'Pinegrove', 'Pink Cafe', 'Pink Floyd', 'PinkPantheress', 'Pistol Annies', 'Placebo', 'Planttvibes', 'Plastic Glass', 'Playaz Circle', 'Playboi Carti', 'Playdate', 'Plies', \"Poor Man's Poison\", 'Pop Dogg', 'Popp Hunna', 'Porches', 'Porkboii', 'Porpura', 'Portishead', 'Portugal. The Man', 'Positive K', 'Powderfinger', 'Powfu', 'Pras', 'Precedence', 'Prefab Sprout', 'Pretty Ricky', 'Prince', 'Prince Fatty', 'Prince Royce', 'Priscilla Block', 'Priscilla Renea', 'Project North', 'Projected Twin', 'Protoje', 'Próxima Parada', 'Public Library Commute', 'Puma Blue', 'Q', 'Q-Tip', 'QUEEN OMARA', 'Quality Control', 'Quarters of Change', 'Queen Naija', 'Queen Nu', 'Quiet Company', 'Quincy Jones', 'R. City', 'R. Kelly', 'RAEYA', 'RAT BOY', 'RAYGUN CARVER', 'RINI', 'RL Grime', 'Rachel Chinouriri', 'Rae Sremmurd', 'Raedio', 'Raging Fyah', 'Rainbow Kitten Surprise', 'Ralph Felix', 'Ralph McDonald', 'Randy Crawford', 'Randy Houser', 'Rangga Jones', 'Raquel', 'Ratt', 'Rauf & Faik', 'Ray Bull', 'Ray J', 'Ray Parker Jr.', 'Ray Price', 'Ray Rich FMG', 'Raynes', 'Razorlight', 'Reaal', 'RealestK', 'Reamonn', 'Rebecca Black', 'Rebelution', 'Rebounder', 'Red Sovine', 'Redbone', 'Redferrin', 'Reef', 'Reeve Carney', 'Rehab', 'Relient K', 'Remi Wolf', 'Remy Ma', 'Ren', 'Renee Olstead', 'Reneé Rapp', 'Reverend And The Makers', 'Rex Orange County', 'Reymil', 'Rhett Akins', 'Rich Amiri', 'Rich Gang', 'Rich Homie Quan', 'Rich The Kid', 'Richard Hawley', 'Richie Havens', 'Richie Spice', 'Rick James', 'Rick Springfield', 'Ricky Martin', 'Rigel Crux', 'Right Said Fred', 'Rilo Kiley', 'Rio Romeo', \"Rippin' Cigs\", 'Rise Against', 'Rob $tone', 'Rob Wolf', 'Robbie Tripp', 'Robbie Williams', 'Robert DeLong', 'Robert Grace', 'Roberta Flack', 'Robin Gibb', 'Robyn', 'Rocco DeLuca', 'Rochdale', 'Roderick Porter', 'Rodney Atkins', 'Rogue Wave', 'Roll Deep', 'Romeo Santos', 'Ronan Keating', 'Ronnie Milsap', 'Room 5', 'Rosa Linn', 'Rosalyn', 'Rose Royce', 'Ross Lynch', 'Rowan Blanchard', 'Roxette', 'Roy Hargrove', 'Roy Jones Jr.', 'Royel Otis', 'Ruff Endz', 'Rufus', 'Rufus & Carla', 'Rundown Spaz', 'Run–D.M.C.', 'Rupee', 'Rupert Holmes', 'Russ', 'Rusted Root', 'Rusty Gear', 'Rvshvd', 'Ryan Caraveo', 'Ryan Hurd', 'Ryan Leslie', 'Ryan Oakes', 'Ryan.B', 'Ryn Weaver', 'RŮDE', 'S Club', \"S'Express\", 'S1mba', 'SALES', 'SAULT', 'SAYGRACE', 'SCRUBB', 'SEB', 'SHOP BOYZ', 'SIX60', 'SNBRN', 'SOJA', 'SOLOMON', 'SR-71', 'STRFKR', 'SWV', 'SYML', 'Sabina Ddumba', 'Sabrina', 'Sabrina Claudio', 'Sacropolis', 'Sade', 'Sadie Hawkins', 'Sage The Gemini', 'Saian Supa Crew', 'Saint Raymond', 'Salami Rose Joe Louis', 'Salt-N-Pepa', 'Sam Barber', 'Sam Cooke', 'Sam Fischer', 'Sam Kim', 'Sam Ock', 'Sam Sparro', 'Sam Wills', 'Samantha Fox', 'Samm Henshaw', 'Sammy Adams', 'Sammy Kershaw', 'Samuel Barber', 'Samuel Coleridge-Taylor', 'Sananda Maitreya', 'Sandëro', 'Sara Evans', 'Sarah Jaffe', 'Sarah McLachlan', 'Savage Garden', 'Savage Sons', 'Scarlet Pleasure', 'Scatman John', 'Schmarx & Savvy', 'Schoolgirl Byebye', 'Schuyler Fisk', 'Scissor Sisters', 'Scorey', 'Scott James', 'Scott McKenzie', 'Scouting For Girls', 'Sea Lemon', 'Sea Wolf', 'Seaforth', 'Seal', 'Sean Daily', 'Sean Kingston', 'Seann Bowe', 'Seaweed', 'Second Set', 'Seepeoples', 'Selfsteam', 'Semisonic', 'Semmi', 'September', 'Seven Mary Three', 'Shabazz PBG', 'Shabba Ranks', 'Shakaya', 'Shakka', 'Shawn Colvin', 'Shawn Hook', 'Shawn James', 'Shaylen', 'Sheck Wes', 'Shenandoah', 'Shocking Blue', 'Shola Ama', 'Shouse', 'Shwayze', 'Shy Smith', 'SiR', 'Sicksways', 'Sidney Bechet', 'Sigrid', 'Sik World', 'Silentó', 'Silk City', 'Silk Skin Lovers', 'Silversun Pickups', 'Simone Kelly', 'Simply Red', 'Sinitta', 'Sinéad Harnett', 'Sir Mix-A-Lot', 'Sir Speedy', 'Sisqo', 'Sista Prod', 'Six 3', 'Sjowgren', 'Skee-Lo', 'Skeeter Davis', 'Ski Mask The Slump God', 'Skin Yard', 'Skrizzly Adams', 'Sky McCreery', 'Skydiving', 'Slaï', 'Sleep Token', 'Slim Guerilla', 'Slowdive', 'Sly & The Family Stone', 'Small Forward', 'Smif-N-Wessun', 'Smiley', 'Smith & Thell', 'Smokepurpp', 'Snail Mail', 'Snakehips', 'Snug', 'Sobs', 'Soccer Mommy', 'Sofia Mills', 'Soft Launch', \"Someone Else's Rain\", 'Something Corporate', 'Sonder', 'Sonique', 'Sonny Clark', 'Sonny Clark Trio', 'Sonny Rollins', 'Sonny Rollins Quartet', 'Sophia Gonzon', 'Sophie B. Hawkins', 'Sophie Ellis-Bextor', 'Soul For Real', 'Soul II Soul', 'Souls Of Mischief', 'South Bad Boy', 'Spacey Jane', 'Speak', 'Sped Up Songs + Nightcore', 'Speedy Jack', 'Spendtime Palace', 'Spice Girls', 'Spin Doctors', 'Spliff', 'Sponge', 'Spoon', 'Spottie WiFi', 'Stacey Kent', 'Stan Walker', 'Stand Atlantic', 'Stanley Myers', 'Stanley Turrentine', 'Star 2', 'Stardust', 'Starley', 'Stars', 'Starship', 'StaySolidRocky', 'Stepdad', 'Stephanie Laurence', 'Stephanie Poetri', 'Stephen Dawes', 'Stephen Swartz', 'Stereo Dub', 'Stereophonics', 'Steve Kekana', 'Steve Lacy', 'Steve Tyrell', 'Steve Winwood', 'Stevie Nicks', 'Sticky Fingers', 'Stomy Bugsy', 'Stormaxxi', 'Strandz', 'Styles P', 'SuaveBoyKB', 'Subsonic Eye', 'Sueco', 'Sugababes', 'Sugar Ray', 'Sugarcult', 'Sugarland', 'Sugiwon', 'Suite Mentale', 'Summer Heart', 'Summer Salt', 'Summer Walker', 'Summerdrive', 'Sun Rai', 'Sundara Karma', 'Supergrass', 'Supermode', 'Sure Sure', 'Survivor', 'Sushi Soucy', 'Suzanne Vega', 'Suzi', 'Swamp District', 'Swann Sands', 'Sweet William', 'Sweet and Lonely', 'Swilson', 'Switchfoot', 'Swoltie', 'Sylo', 'Sóley', 'TEMPOREX', 'THE DRIVER ERA', 'THE S.L.P.', 'THE SCOTTS', 'THEY.', 'TJ Mello', 'TLC', 'TOLEDO', 'TQ', 'TUSHAR', 'TYuS', 'Tad', 'Tag Team', 'Taio Cruz', 'Takayoshi', 'Take That', 'Taking Back Sunday', 'Tal Bachman', 'Talain Rayne', 'Tally Hall', 'Tammy Wynette', 'Tanner Adell', 'Tay-K', 'Taylor Bickett', 'Taylor Dayne', 'Teddy Pendergrass', 'Teddy Swims', 'Tee Grizzley', 'Teen Jesus and the Jean Teasers', 'Temple Island', 'Tems', 'Ten Tonnes', 'Tenacious D', 'Teqkoi', 'Teriyaki Boyz', 'Terror Squad', 'Terry and The Dustriders', 'Tess Posner', 'Texas', 'Tez Cadey', 'Thad Jones', 'The 502s', 'The Academic', 'The Alan Parsons Project', 'The All Seeing I', 'The Amazons', 'The Ark', 'The Asteroids Galaxy Tour', 'The Ataris', 'The Avalanches', 'The Band Perry', 'The Bangles', 'The Beach Boys', 'The Beaches', 'The Beatles', 'The Bellamy Brothers', 'The Belle Brigade', 'The Ben Webster Quintet', 'The Blow Monkeys', 'The Boom Circuits', 'The Box Tops', 'The Bravery', 'The Breeders', 'The Calling', 'The Cardigans', 'The Cat Empire', 'The Charlie Daniels Band', 'The Chemical Brothers', 'The Chevin', 'The Chicks', 'The Chords', 'The City of Prague Philharmonic Orchestra', 'The Clamor', 'The Clocks', 'The Conall Band', 'The Contours', 'The Coral', 'The Coronas', 'The Corrs', 'The Crew Cuts', 'The Cribs', 'The Dandy Warhols', 'The Dead South', 'The Drums', 'The Emotions', 'The Enemy', 'The Features', 'The Feeling', 'The First Edition', 'The Fratellis', 'The Futureheads', 'The Game', 'The Greeting Committee', 'The Growlers', 'The Guess Who', 'The Hails', 'The Highwaymen', 'The Hives', 'The Hollies', 'The Honey Trees', 'The Honeysticks', 'The Hoosiers', 'The Horn', 'The Hourglass Effect', 'The Hunna', 'The Icarus Account', 'The Ink Spots', 'The Island Caribbean Steel Drum Band', 'The Isley Brothers', 'The Jacksons', 'The Joy Formidable', 'The Judds', 'The Kaizens', 'The Kiffness', 'The Kinks', 'The Last Dinner Party', 'The Last Goodnight', 'The Last Shadow Puppets', 'The Lathums', 'The Lester Young - Teddy Wilson Quartet', 'The Libertines', 'The Lighthouse And The Whaler', 'The Lily Dippers', 'The Limousines', 'The Living Tombstone', 'The Lonely Forest', 'The Lonely Island', \"The Lovin' Spoonful\", 'The Maccabees', 'The Magic Numbers', 'The Manhattans', 'The Marvelettes', 'The Melodians', 'The Memory Band', 'The Merrymen', 'The Meters', 'The Middle East', 'The Millennial Club', 'The Modern Jazz Quartet', 'The Moldy Peaches', 'The Monty Alexander Trio', 'The Morning Benders', 'The Moss', \"The Mowgli's\", 'The Naked And Famous', 'The Oak Ridge Boys', 'The Ordinary Boys', 'The Pasadenas', 'The Pharcyde', 'The Pigeon Detectives', 'The Pointer Sisters', 'The Postal Service', 'The Pretty Reckless', 'The Proclaimers', 'The Pussycat Dolls', 'The Rasmus', 'The Real Thing', 'The Red Clay Strays', 'The Reign of Kindo', 'The Rembrandts', 'The Revivalists', 'The Reytons', 'The Ricca Project', 'The Rifles', 'The Rolling Stones', 'The Roots', 'The Royal Concept', 'The Royalty', 'The Rumble Strips', 'The Saturdays', 'The Sherlocks', 'The Snuts', 'The Sometimes Island', 'The Space Ocean', 'The Specials', 'The Spinners', 'The Spring Standards', 'The Staycations', 'The Stone Roses', 'The Stooges', 'The Story So Far', 'The Streets', 'The Strypes', 'The Subways', 'The Sugarhill Gang', 'The Sun Kings', 'The Supermen Lovers', 'The Supremes', 'The Tano Jones Revelry', 'The Temper Trap', 'The The', 'The Ting Tings', 'The Tokens', 'The Trashmen', 'The Troggs', 'The Turtles', 'The Undertones', 'The Urban Tales', 'The Used', 'The Vaccines', 'The Vices', 'The View', 'The Wailers', 'The Walkers', 'The Wannadies', 'The Warhawks', 'The Weather Girls', 'The Whitest Boy Alive', 'The Wreckers', 'The Young International', 'The Zombies', 'The Zutons', 'Thee Sacred Souls', 'Thelonious Monk Quartet', 'Theo Tams', 'Therapy?', 'Third World', 'Thompson Square', 'Three 6 Mafia', 'Thundercat', 'ThxSoMch', 'Tia Blake', 'Tiera Kennedy', 'Tiffany Day', 'Tiffany Woys', 'Tight Fit', 'Tigirlily Gold', 'Tim Berg', 'Timmy Thomas', 'Tina Turner', 'Tinchy Stryder', 'Tink', 'Tipling Rock', 'Toddla T', 'Tokio Hotel', 'Tokyo Police Club', 'Tom Cochrane', 'Tom Jones', 'Tom Meighan', 'Tom Misch', 'Tom Odell', 'Tom Penny', 'Tom Rosenthal', 'Tom T. Hall', 'Tommy Boi', 'Tommy James & The Shondells', 'TommyMuzzic', 'Tones And I', 'Tony22', 'Too $hort', 'Toots & The Maytals', 'Toots Thielemans', 'Tooz', 'Tophouse', 'Tors', 'Towa Bird', 'Tracy Byrd', 'Trade Union', 'Trae Tha Truth', 'Tragic Love Company', 'TrashAssMusic', 'Travie McCoy', 'Travis', 'Travis Porter', 'Travis Thamert', 'Tre Svaint', 'Treaty Oak Revival', 'Trey Bryant', 'Trey Lewis', 'Trey Songz', 'Trick Daddy', 'Trinix Remix', 'Tripz', 'Troy', 'Troy Ave', 'Truth Hurts', 'Truxton Mile', 'Tucker Wetmore', 'Tweet', 'Twin Shadow', 'Two Door Cinema Club', 'Ty Gregory', 'Ty Myers', 'Ty Stonehawker', 'Tycho', 'Tyla', 'Tyla Yaweh', 'Tyler Bond', 'Tyler Burkhart', 'Tyler Hursey', 'Tyler James Williams', 'Tyrese', 'U.S. Royalty', 'U2', 'UCHE YARA', 'UGK', 'UMI', 'UNEJ', 'UR SO', 'USHER', 'Uncle Lucius', 'Unk', 'Unprocessed', 'Urge Overkill', 'V V Brown', 'V.I.C.', 'VANT', 'VARIATION', 'VDO', 'VIC MENSA', 'Van Morrison', 'Vanessa Doll', 'Vanilla Ice', 'Various Artists', 'VeggieTales', 'Velvet Wasted', 'Vera Blue', 'Vertical Horizon', 'Vian Izak', 'Victor Ray', 'Victor Thompson', 'Victoria Monét', 'Victorious Cast', 'Video Age', 'Vierre Cloud', 'Village People', 'Vincent Scotto', 'Viola Beach', 'Vluestar', 'Volt', 'Vundabar', 'VØJ', 'WATCH THE DUCK', 'WICKED', 'WILLIS', 'Wadiya Productions', 'Wailing Souls', 'Waka Flocka Flame', 'Wale', 'Walk off the Earth', 'Walter Murphy', 'War', 'Warm Brew', 'Warrant', 'Warren G', 'Warren Zeiders', 'Wasia Project', 'Waterfront Wranglers', 'Wayland', 'Waylon Hanel', 'Waylon Jennings', 'Wayne Shorter', 'Wayne Wade', 'Wayne Wonder', 'We Are Scientists', 'We Were Promised Jetpacks', 'Weather Report', 'Wendy Rene', 'Wes Montgomery', 'Wes Walker', 'WesGhost', 'Westlife', 'Westside Connection', 'Wet Leg', 'Wheatus', 'White Rabbits', 'White Town', 'Whitley', 'Wild Cherry', 'Wild Cub', 'Wiley', 'Will Morton', 'Will Roush', 'Will To Power', 'Will Young', 'Willa Ford', 'Willamette Stone', 'William Walton', 'Willliam Walton', 'Wilson Pickett', 'Wings', 'Winnetka Bowling League', 'Winona Fighter', 'Witchz', 'With Confidence', 'Womack & Womack', 'Wreckx-N-Effect', 'Wrongtom', 'Wu-Tang Clan', 'Wuki', 'Wunderhorse', 'Wyatt Flores', 'Wynton Marsalis', 'Wynton Marsalis Septet', 'XSpence', 'Xcellence!', 'Xuitcasecity', 'Y2K', 'YBN Nahmir', 'YG Marley', 'YNW Melly', 'Yall', 'Yam Haus', 'Yeat', 'Yebba', 'Yella Mann', 'Ying Yang Twins', 'Ylona Garcia', 'Ylvis', 'Yng Lvcas', 'Yo Gotti', 'Yolanda Be Cool', 'Young Bombs', 'Young Dolph', 'Young M.A', 'Young Money', 'Young Stoner Life', 'YoungBoy Never Broke Again', 'Youngblood Hawke', 'Youngbloodz', 'Your Favorite Down South Supplier', 'Youth Group', 'Youth Killed It', 'Yung Berg', 'Yung Joc', 'Yung Lean', 'Yung Pinch', 'Yuno', 'Yusef Lateef', 'Yusuf / Cat Stevens', 'Zac Brown Band', 'Zac Efron', 'Zac Greer', 'Zach Templar', 'Zelron', 'Zeph', 'Zhané', 'Zoe Ko', 'Zolita', '[Kyle Davis]', 'a kid named rufus', 'almost monday', 'alt-J', 'anees', 'banzai florist', 'basecamp', 'bbno$', 'bby', 'bixby', 'boy pablo', 'boygenius', 'cassö', 'clide', 'corook', 'd4vd', 'daydreamers', 'demxntia', 'dj 6rb', 'dodie', 'eli.', 'eliii', 'feeble little horse', 'fern', 'flipturn', 'flowerovlove', 'fragile flamingo', 'gianni & kyle', 'girli', 'grentperez', 'hanbee', 'hanuel', 'hey, nothing', 'hunter & wolfe', 'iNi Kamoze', 'iamjakehill', 'ilyTOMMY', 'iñigo quintero', 'jagger finn', 'juju<3', 'june', 'juno roome', 'keshi', 'khai dreams', 'killkiyoshi', 'late night drive home', 'lilbubblegum', 'lofi.samurai', 'mansionz', 'metr', 'mgk', 'morgxn', 'mousike', 'mxmtoon', 'pearl', 'pizzaboys', 'pluko', 'quinnie', 'raph', 're6ce', 'sadeyes', 'sagun', 'salvia palth', 'slchld', 'slowthai', 'sombr', 'space x', 'spring gang', 'sunkis', 'sunshine blvd.', 't.A.T.u.', 'the booyah! kids', 'theguiltyparty.', 'thủy', 'untrusted', 'wave to earth', 'wes', 'whyetc', 'will.i.am', 'yaeow', 'ymf', '¥$', 'ØZI', 'Ūla', '動物園釘子戶', '恐龍的皮', '落日飛車 Sunset Rollercoaster', '高爾宣 OSN'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Add genres to the dataset\n",
    "full_dataset_df[\"genre\"] = get_genres(full_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "HeqZ-wRaYydj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeqZ-wRaYydj",
    "outputId": "4be5c99b-7602-4bab-9618-c0d757ebf880"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any rows where genres are null\n",
    "full_dataset_df[\"genre\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "USbU707s30Bj",
   "metadata": {
    "id": "USbU707s30Bj"
   },
   "source": [
    "As you can see we successfully got the genres for all rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_PhN5NfM4ACs",
   "metadata": {
    "id": "_PhN5NfM4ACs"
   },
   "source": [
    "## Data Preparation - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wdobV04w4Etl",
   "metadata": {
    "id": "wdobV04w4Etl"
   },
   "source": [
    "We will now be preprocessing our data, by making all categorical features numeric. We will be making use of one-hot encoding to do so. <br>\n",
    "\n",
    "Then, we will make use of an autoencoder model to further reduce the dimensionality and improve the richness of the features of our model. <br>\n",
    "\n",
    "Then, we will be scaling and normalising our features before finally making use of them in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54a65d50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54a65d50",
    "outputId": "4b531222-4389-4404-a262-43983305c487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11793 entries, 0 to 17579\n",
      "Data columns (total 38 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Track Name        11793 non-null  object \n",
      " 1   artists           11793 non-null  object \n",
      " 2   popularity        11793 non-null  int64  \n",
      " 3   release_year      11793 non-null  int64  \n",
      " 4   danceability      11793 non-null  float64\n",
      " 5   energy            11793 non-null  float64\n",
      " 6   loudness          11793 non-null  float64\n",
      " 7   speechiness       11793 non-null  float64\n",
      " 8   acousticness      11793 non-null  float64\n",
      " 9   instrumentalness  11793 non-null  float64\n",
      " 10  liveness          11793 non-null  float64\n",
      " 11  valence           11793 non-null  float64\n",
      " 12  tempo             11793 non-null  float64\n",
      " 13  duration_ms       11793 non-null  int64  \n",
      " 14  time_signature    11793 non-null  int64  \n",
      " 15  key_0             11793 non-null  int64  \n",
      " 16  key_1             11793 non-null  int64  \n",
      " 17  key_2             11793 non-null  int64  \n",
      " 18  key_3             11793 non-null  int64  \n",
      " 19  key_4             11793 non-null  int64  \n",
      " 20  key_5             11793 non-null  int64  \n",
      " 21  key_6             11793 non-null  int64  \n",
      " 22  key_7             11793 non-null  int64  \n",
      " 23  key_8             11793 non-null  int64  \n",
      " 24  key_9             11793 non-null  int64  \n",
      " 25  key_10            11793 non-null  int64  \n",
      " 26  key_11            11793 non-null  int64  \n",
      " 27  mode_0            11793 non-null  int64  \n",
      " 28  mode_1            11793 non-null  int64  \n",
      " 29  genre_0           11793 non-null  int64  \n",
      " 30  genre_1           11793 non-null  int64  \n",
      " 31  genre_2           11793 non-null  int64  \n",
      " 32  genre_3           11793 non-null  int64  \n",
      " 33  genre_4           11793 non-null  int64  \n",
      " 34  genre_5           11793 non-null  int64  \n",
      " 35  genre_6           11793 non-null  int64  \n",
      " 36  explicit_False    11793 non-null  int64  \n",
      " 37  explicit_True     11793 non-null  int64  \n",
      "dtypes: float64(9), int64(27), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "categorical_features = ['key', 'mode', 'genre','explicit']\n",
    "numerical_features = ['duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','popularity']\n",
    "full_dataset_df = pd.get_dummies(full_dataset_df, columns=categorical_features)\n",
    "\n",
    "# Listout one-Hot encoded features\n",
    "final_categorical_features = ['key_0','key_1','key_2','key_3','key_4','key_5','key_6','key_7','key_8','key_9','key_10','key_11','mode_0','mode_1', 'genre_0', 'genre_1', 'genre_2', 'genre_3', 'genre_4', 'genre_5', 'genre_6','explicit_False','explicit_True']\n",
    "for column in final_categorical_features:\n",
    "    full_dataset_df[column] = full_dataset_df[column].astype(int)\n",
    "\n",
    "full_dataset_df.info()\n",
    "\n",
    "scaled_full_dataset_df = full_dataset_df.copy()\n",
    "scaled_full_dataset_df[numerical_features] = scaler.fit_transform(scaled_full_dataset_df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lfn03rvLFInu",
   "metadata": {
    "id": "Lfn03rvLFInu"
   },
   "source": [
    "## Autoencoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aoFV83QFNwK",
   "metadata": {
    "id": "8aoFV83QFNwK"
   },
   "source": [
    "To achieve dimensionality reduction, one of the methods that we will be using is an **Autoencoder neural network**. An autoencoder is made out of 2 parts, an encoder and a decoder. The encoder section applies transformations onto the input data, **reducing the dimensionality of data** in each layer. This is done until it reaches a low-dimensional bottleneck. This bottleneck captures the essential features of the data. The decoder then tries to **reconstruct the original data** from this compressed representation. How different the resulting output is from the original is taken as the **loss function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TANx0B1BM4h2",
   "metadata": {
    "id": "TANx0B1BM4h2"
   },
   "source": [
    "### Unweighted autoencoder model\n",
    "The Unweighted Autoencoder **does not assign different importances to different features** when calculating the loss during training. It treats all errors between the reconstructed output and the original input equally across the dataset. This is useful for dataset with features that have around the same importances and is generally simpler than the weighted variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "TtHvcIp5M9vi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtHvcIp5M9vi",
    "outputId": "fe778c23-1ac3-4c00-e22d-34099c59b905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 23:50:57.765613: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 8ms/step - loss: 1580289664.0000 - val_loss: 1271458432.0000\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1578274048.0000 - val_loss: 1270493056.0000\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1577365248.0000 - val_loss: 1269969536.0000\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576871808.0000 - val_loss: 1269691776.0000\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576615552.0000 - val_loss: 1269550336.0000\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576488192.0000 - val_loss: 1269483136.0000\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576428672.0000 - val_loss: 1269452544.0000\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576401920.0000 - val_loss: 1269439488.0000\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576390912.0000 - val_loss: 1269434368.0000\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576386560.0000 - val_loss: 1269432320.0000\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 1576384768.0000 - val_loss: 1269431552.0000\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576384128.0000 - val_loss: 1269431424.0000\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 1576384384.0000 - val_loss: 1269431296.0000\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 1s 28ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576383744.0000 - val_loss: 1269431296.0000\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 1576383616.0000 - val_loss: 1269431296.0000\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 1576383872.0000 - val_loss: 1269431296.0000\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576383872.0000 - val_loss: 1269431296.0000\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576383744.0000 - val_loss: 1269431296.0000\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576383872.0000 - val_loss: 1269431296.0000\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576384256.0000 - val_loss: 1269431296.0000\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576383872.0000 - val_loss: 1269431296.0000\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576383872.0000 - val_loss: 1269431296.0000\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576383744.0000 - val_loss: 1269431296.0000\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576384128.0000 - val_loss: 1269431296.0000\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576384000.0000 - val_loss: 1269431296.0000\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576383872.0000 - val_loss: 1269431296.0000\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576383872.0000 - val_loss: 1269431296.0000\n"
     ]
    }
   ],
   "source": [
    "# Exclude non-numeric features like 'Track Name', 'Artist Name' for input\n",
    "input_dim = full_dataset_df.shape[1] - 2\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_value = 20\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Encoder/Decoder definition (Hyperparameters were tuned such that optimal results were given)\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(128, activation='relu', activity_regularizer=l1_l2(l1=1e-5, l2=1e-4))(input_layer)\n",
    "encoded = Dropout(0.1)(encoded)\n",
    "encoded = Dense(68, activation='relu', activity_regularizer=l1_l2(l1=1e-5, l2=1e-4))(encoded)\n",
    "encoded = Dropout(0.1)(encoded)\n",
    "encoded = Dense(40, activation='relu', activity_regularizer=l1_l2(l1=1e-5, l2=1e-4))(encoded)\n",
    "decoded = Dense(68, activation='relu')(encoded)\n",
    "decoded = Dropout(0.1)(decoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dropout(0.1)(decoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Compile the autoencoder\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Prepare data for training\n",
    "\n",
    "# Use numeric data only\n",
    "X_train = full_dataset_df.drop(['Track Name', 'artists'], axis=1)\n",
    "\n",
    "# Convert to float32 to ensure compatibility with TensorFlow\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=256, validation_split=0.2)\n",
    "\n",
    "# Create a separate encoder model from the full autoencoder\n",
    "unweighted_encoder = Model(input_layer, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5DXEbasM0OM",
   "metadata": {
    "id": "f5DXEbasM0OM"
   },
   "source": [
    "### Weighted autoencoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae033197",
   "metadata": {},
   "source": [
    "The Weighted Autoencoder can **assign different weights to features**, allowing the model to prioritise minimising the error cost of specific features over the others during training. In this autoencoder model, we will be adjusting the weights based on the feature importance in deciding a song's popularity that we found earlier in the second notebook (Part 2: Music Popularity Model). \n",
    "\n",
    "The weights of **music genre, explicit lyrics, release year, instrumentalness** will be adjusted upwards while the weights of **key, mode and danceability** are adjusted downwards. Artist names are not included in our recommender system as it requires multilabel binarizer and will create too many features for our small-scaled recommender system. \n",
    "\n",
    "From experience, we found that, specifically for the autoencoder, improving the weight of speechiness was also important in improving the quality of recommendations. Given the black box nature of Neural Networks and AI, we are not able to give a reason why at this moment.\n",
    "\n",
    "We will be simulating this in the model by simply multiplying the values by a number greater than one for the more important features, and a number less than one for a less important feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "zMcD4gQDBb1z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zMcD4gQDBb1z",
    "outputId": "707fe163-dd0f-4bfd-9079-673e2141c138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "37/37 [==============================] - 1s 7ms/step - loss: 1580514304.0000 - val_loss: 1271646336.0000\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1578505088.0000 - val_loss: 1270748160.0000\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1577633408.0000 - val_loss: 1270227840.0000\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1577134080.0000 - val_loss: 1269937792.0000\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576861184.0000 - val_loss: 1269784192.0000\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576720000.0000 - val_loss: 1269707648.0000\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576650880.0000 - val_loss: 1269671424.0000\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576619136.0000 - val_loss: 1269655552.0000\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576605440.0000 - val_loss: 1269648640.0000\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576599680.0000 - val_loss: 1269645952.0000\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1576597120.0000 - val_loss: 1269644800.0000\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576596352.0000 - val_loss: 1269644544.0000\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576596096.0000 - val_loss: 1269644544.0000\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576596096.0000 - val_loss: 1269644544.0000\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 1576595584.0000 - val_loss: 1269644544.0000\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595456.0000 - val_loss: 1269644544.0000\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595456.0000 - val_loss: 1269644544.0000\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595584.0000 - val_loss: 1269644544.0000\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595968.0000 - val_loss: 1269644544.0000\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576595584.0000 - val_loss: 1269644544.0000\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576595968.0000 - val_loss: 1269644544.0000\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576595456.0000 - val_loss: 1269644544.0000\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576595584.0000 - val_loss: 1269644544.0000\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595968.0000 - val_loss: 1269644544.0000\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576595840.0000 - val_loss: 1269644544.0000\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 1576595584.0000 - val_loss: 1269644544.0000\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576595584.0000 - val_loss: 1269644544.0000\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576595712.0000 - val_loss: 1269644544.0000\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1576595584.0000 - val_loss: 1269644544.0000\n"
     ]
    }
   ],
   "source": [
    "# Exclude non-numeric features: 'Track Name', 'Artist Name' for input\n",
    "input_dim = full_dataset_df.shape[1] - 2\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_value = 21\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Encoder/Decoder definition (Hyperparameters were tuned such that optimal results were given)\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(128, activation='relu', activity_regularizer=l1_l2(l1=1e-5, l2=1e-4))(input_layer)\n",
    "encoded = Dropout(0.1)(encoded)\n",
    "encoded = Dense(68, activation='relu', activity_regularizer=l1_l2(l1=1e-5, l2=1e-4))(encoded)\n",
    "encoded = Dropout(0.1)(encoded)\n",
    "encoded = Dense(40, activation='relu', activity_regularizer=l1_l2(l1=1e-5, l2=1e-4))(encoded)\n",
    "decoded = Dense(68, activation='relu')(encoded)\n",
    "decoded = Dropout(0.1)(decoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dropout(0.1)(decoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Prepare data for training\n",
    "# Use numeric data only\n",
    "X_train = full_dataset_df.drop(['Track Name', 'artists'], axis=1)\n",
    "\n",
    "# Convert to float32 to ensure compatibility with TensorFlow\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "# music genre, explicit lyrics, release year, instrumentalness\n",
    "# Adjust the weights of different values for the model\n",
    "# key, mode and danceability are adjusted downwards as \n",
    "X_train[['key_0','key_1','key_2','key_3','key_4','key_5','key_6','key_7','key_8','key_9','key_10','key_11']] *= 0.90\n",
    "X_train[['mode_0','mode_1']] *= 0.95\n",
    "X_train['danceability'] *= 0.94\n",
    "X_train['instrumentalness'] *= 1.5\n",
    "X_train['release_year'] *= 1.7\n",
    "X_train['speechiness'] *= 1.5\n",
    "X_train[['explicit_False','explicit_True']] *= 1.1\n",
    "X_train['popularity'] *= 1.7\n",
    "X_train[['genre_0','genre_1','genre_3','genre_4','genre_5','genre_6']] *= 1.4\n",
    "X_train['genre_2'] *= 1.3\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=256, validation_split=0.2)\n",
    "\n",
    "# Create a separate encoder model from the full autoencoder\n",
    "weighted_encoder = Model(input_layer, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gzS20ZDDNpEV",
   "metadata": {
    "id": "gzS20ZDDNpEV"
   },
   "source": [
    "Now, we have done all the relevant preprocessing and preparation with our main dataset. We will now preprocess and prepare our user playlist dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NlPSIydI47Fr",
   "metadata": {
    "id": "NlPSIydI47Fr"
   },
   "source": [
    "## Preprocessing and preparing user playlist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pCcT27JqEqLu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "pCcT27JqEqLu",
    "outputId": "db227019-df81-4d72-ce25-10807955c1d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syed_aliredha/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['A-Wall', 'Arctic Monkeys', 'BØRNS', 'Dayglow', 'Joji', 'Rex Orange County'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>artists</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLOW DANCING IN THE DARK</td>\n",
       "      <td>Joji</td>\n",
       "      <td>49</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.479</td>\n",
       "      <td>3</td>\n",
       "      <td>-7.458</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.54400</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.284</td>\n",
       "      <td>88.964</td>\n",
       "      <td>209274</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>505</td>\n",
       "      <td>Arctic Monkeys</td>\n",
       "      <td>81</td>\n",
       "      <td>2007</td>\n",
       "      <td>False</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.866</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.00237</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.234</td>\n",
       "      <td>140.267</td>\n",
       "      <td>253587</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sweater Weather</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "      <td>90</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.807</td>\n",
       "      <td>10</td>\n",
       "      <td>-2.810</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.04950</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.398</td>\n",
       "      <td>124.053</td>\n",
       "      <td>240400</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are You Bored Yet? (feat. Clairo)</td>\n",
       "      <td>Wallows</td>\n",
       "      <td>83</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.683</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.444</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.15600</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>0.640</td>\n",
       "      <td>120.023</td>\n",
       "      <td>178000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Young Dumb &amp; Broke</td>\n",
       "      <td>Khalid</td>\n",
       "      <td>82</td>\n",
       "      <td>2017</td>\n",
       "      <td>False</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.539</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.351</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.394</td>\n",
       "      <td>136.948</td>\n",
       "      <td>202547</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Track Name            artists  popularity  \\\n",
       "0           SLOW DANCING IN THE DARK               Joji          49   \n",
       "1                                505     Arctic Monkeys          81   \n",
       "2                    Sweater Weather  The Neighbourhood          90   \n",
       "3  Are You Bored Yet? (feat. Clairo)            Wallows          83   \n",
       "4                 Young Dumb & Broke             Khalid          82   \n",
       "\n",
       "  release_year  explicit  danceability  energy  key  loudness  mode  \\\n",
       "0         2018      True         0.515   0.479    3    -7.458     1   \n",
       "1         2007     False         0.520   0.852    0    -5.866     1   \n",
       "2         2013     False         0.612   0.807   10    -2.810     1   \n",
       "3         2019     False         0.682   0.683    8    -6.444     0   \n",
       "4         2017     False         0.799   0.539    1    -6.351     1   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0261       0.54400          0.005980    0.1910    0.284   88.964   \n",
       "1       0.0543       0.00237          0.000058    0.0733    0.234  140.267   \n",
       "2       0.0336       0.04950          0.017700    0.1010    0.398  124.053   \n",
       "3       0.0287       0.15600          0.000023    0.2730    0.640  120.023   \n",
       "4       0.0421       0.19900          0.000017    0.1650    0.394  136.948   \n",
       "\n",
       "   duration_ms  time_signature  genre  \n",
       "0       209274               4      2  \n",
       "1       253587               4      5  \n",
       "2       240400               4      6  \n",
       "3       178000               4      5  \n",
       "4       202547               4      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the features of the user playlist\n",
    "playlist_features_df = get_audio_info_from_playlist('spotify:playlist:5ZbOfWEU7hok5xNqN2vuc0', sp)\n",
    "playlist_features_df['genre'] = get_genres(playlist_features_df)\n",
    "playlist_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7kBiWC6TbJ2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kBiWC6TbJ2b",
    "outputId": "21b69186-446a-4b3c-f02a-5f7d8403e80a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Track Name        24 non-null     object \n",
      " 1   artists           24 non-null     object \n",
      " 2   popularity        24 non-null     int64  \n",
      " 3   release_year      24 non-null     object \n",
      " 4   explicit          24 non-null     bool   \n",
      " 5   danceability      24 non-null     float64\n",
      " 6   energy            24 non-null     float64\n",
      " 7   key               24 non-null     int64  \n",
      " 8   loudness          24 non-null     float64\n",
      " 9   mode              24 non-null     int64  \n",
      " 10  speechiness       24 non-null     float64\n",
      " 11  acousticness      24 non-null     float64\n",
      " 12  instrumentalness  24 non-null     float64\n",
      " 13  liveness          24 non-null     float64\n",
      " 14  valence           24 non-null     float64\n",
      " 15  tempo             24 non-null     float64\n",
      " 16  duration_ms       24 non-null     int64  \n",
      " 17  time_signature    24 non-null     int64  \n",
      " 18  genre             24 non-null     int64  \n",
      "dtypes: bool(1), float64(9), int64(6), object(3)\n",
      "memory usage: 3.5+ KB\n"
     ]
    }
   ],
   "source": [
    "playlist_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "yEDMCQ9WepTZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEDMCQ9WepTZ",
    "outputId": "52e8bace-a0e4-4309-a526-e8ff4f116cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 38 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Track Name        24 non-null     object \n",
      " 1   artists           24 non-null     object \n",
      " 2   popularity        24 non-null     int64  \n",
      " 3   release_year      24 non-null     int64  \n",
      " 4   danceability      24 non-null     float64\n",
      " 5   energy            24 non-null     float64\n",
      " 6   loudness          24 non-null     float64\n",
      " 7   speechiness       24 non-null     float64\n",
      " 8   acousticness      24 non-null     float64\n",
      " 9   instrumentalness  24 non-null     float64\n",
      " 10  liveness          24 non-null     float64\n",
      " 11  valence           24 non-null     float64\n",
      " 12  tempo             24 non-null     float64\n",
      " 13  duration_ms       24 non-null     int64  \n",
      " 14  time_signature    24 non-null     int64  \n",
      " 15  key_0             24 non-null     int64  \n",
      " 16  key_1             24 non-null     int64  \n",
      " 17  key_2             24 non-null     int64  \n",
      " 18  key_3             24 non-null     int64  \n",
      " 19  key_4             24 non-null     int64  \n",
      " 20  key_5             24 non-null     int64  \n",
      " 21  key_6             24 non-null     int64  \n",
      " 22  key_7             24 non-null     int64  \n",
      " 23  key_8             24 non-null     int64  \n",
      " 24  key_9             24 non-null     int64  \n",
      " 25  key_10            24 non-null     int64  \n",
      " 26  key_11            24 non-null     int64  \n",
      " 27  mode_0            24 non-null     int64  \n",
      " 28  mode_1            24 non-null     int64  \n",
      " 29  genre_0           24 non-null     int64  \n",
      " 30  genre_1           24 non-null     int64  \n",
      " 31  genre_2           24 non-null     int64  \n",
      " 32  genre_3           24 non-null     int64  \n",
      " 33  genre_4           24 non-null     int64  \n",
      " 34  genre_5           24 non-null     int64  \n",
      " 35  genre_6           24 non-null     int64  \n",
      " 36  explicit_False    24 non-null     int64  \n",
      " 37  explicit_True     24 non-null     int64  \n",
      "dtypes: float64(9), int64(27), object(2)\n",
      "memory usage: 7.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the categorical features\n",
    "playlist_features_df[final_categorical_features] = 0\n",
    "categorical_features = ['key', 'mode', 'genre','explicit']\n",
    "playlist_features_df = pd.get_dummies(playlist_features_df, columns=categorical_features)\n",
    "# Not every value in the categorical features will be present, so to circumvent this\n",
    "# We will be manually putting in every necessary column, and merge them\n",
    "for col in final_categorical_features:\n",
    "    cols_to_merge = [c for c in playlist_features_df.columns if c.startswith(col)]\n",
    "    if len(cols_to_merge) > 1:\n",
    "        # Make use of max function to effectively perform an OR operation across duplicates\n",
    "        playlist_features_df[col] = playlist_features_df[cols_to_merge].max(axis=1)\n",
    "playlist_features_df = playlist_features_df.loc[:,~playlist_features_df.columns.duplicated()].copy()\n",
    "\n",
    "# ensure all correct values are numeric and not of type object\n",
    "for column in (final_categorical_features + [\"release_year\"]):\n",
    "    playlist_features_df[column] = playlist_features_df[column].astype(int)\n",
    "playlist_features_df.info()\n",
    "\n",
    "# Scale the playlist features for the non-autoencoder model\n",
    "scaled_playlist_features_df = playlist_features_df.copy()\n",
    "scaled_playlist_features_df[numerical_features] = scaler.fit_transform(scaled_playlist_features_df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "DJ5D7ftpDSvB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "DJ5D7ftpDSvB",
    "outputId": "0b7ec54e-bc0c-47f2-ae5d-f2ac1dd860b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>artists</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>mode_1</th>\n",
       "      <th>genre_0</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>genre_3</th>\n",
       "      <th>genre_4</th>\n",
       "      <th>genre_5</th>\n",
       "      <th>genre_6</th>\n",
       "      <th>explicit_False</th>\n",
       "      <th>explicit_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLOW DANCING IN THE DARK</td>\n",
       "      <td>Joji</td>\n",
       "      <td>49</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.479</td>\n",
       "      <td>-7.458</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.54400</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>505</td>\n",
       "      <td>Arctic Monkeys</td>\n",
       "      <td>81</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.852</td>\n",
       "      <td>-5.866</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.00237</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sweater Weather</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "      <td>90</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.807</td>\n",
       "      <td>-2.810</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.04950</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are You Bored Yet? (feat. Clairo)</td>\n",
       "      <td>Wallows</td>\n",
       "      <td>83</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-6.444</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.15600</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Young Dumb &amp; Broke</td>\n",
       "      <td>Khalid</td>\n",
       "      <td>82</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.539</td>\n",
       "      <td>-6.351</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Track Name            artists  popularity  \\\n",
       "0           SLOW DANCING IN THE DARK               Joji          49   \n",
       "1                                505     Arctic Monkeys          81   \n",
       "2                    Sweater Weather  The Neighbourhood          90   \n",
       "3  Are You Bored Yet? (feat. Clairo)            Wallows          83   \n",
       "4                 Young Dumb & Broke             Khalid          82   \n",
       "\n",
       "   release_year  danceability  energy  loudness  speechiness  acousticness  \\\n",
       "0          2018         0.515   0.479    -7.458       0.0261       0.54400   \n",
       "1          2007         0.520   0.852    -5.866       0.0543       0.00237   \n",
       "2          2013         0.612   0.807    -2.810       0.0336       0.04950   \n",
       "3          2019         0.682   0.683    -6.444       0.0287       0.15600   \n",
       "4          2017         0.799   0.539    -6.351       0.0421       0.19900   \n",
       "\n",
       "   instrumentalness  ...  mode_1  genre_0  genre_1  genre_2  genre_3  genre_4  \\\n",
       "0          0.005980  ...       1        0        0        1        0        0   \n",
       "1          0.000058  ...       1        0        0        0        0        0   \n",
       "2          0.017700  ...       1        0        0        0        0        0   \n",
       "3          0.000023  ...       0        0        0        0        0        0   \n",
       "4          0.000017  ...       1        1        0        0        0        0   \n",
       "\n",
       "   genre_5  genre_6  explicit_False  explicit_True  \n",
       "0        0        0               0              1  \n",
       "1        1        0               1              0  \n",
       "2        0        1               1              0  \n",
       "3        1        0               1              0  \n",
       "4        0        0               1              0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_fce0pye5yKK",
   "metadata": {
    "id": "_fce0pye5yKK"
   },
   "source": [
    "Now all that we need to do is to apply the Autoencoder and scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bVqeUO7pBp_D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVqeUO7pBp_D",
    "outputId": "f1717a76-7c76-44b1-964c-309a810bc466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 0s 302us/step\n",
      "369/369 [==============================] - 0s 291us/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "unweighted_full_encoded = unweighted_encoder.predict(X_train)\n",
    "weighted_full_encoded = weighted_encoder.predict(X_train)\n",
    "\n",
    "unweighted_playlist_encoded = unweighted_encoder.predict(playlist_features_df.drop(['Track Name', 'artists'], axis=1).astype('float32'))\n",
    "weighted_playlist_encoded = weighted_encoder.predict(playlist_features_df.drop(['Track Name', 'artists'], axis=1).astype('float32'))\n",
    "\n",
    "weighted_full_encoded_scaled = scaler.fit_transform(weighted_full_encoded)\n",
    "unweighted_full_encoded_scaled = scaler.fit_transform(unweighted_full_encoded)\n",
    "\n",
    "unweighted_playlist_encoded_scaled = scaler.transform(unweighted_playlist_encoded)\n",
    "weighted_playlist_encoded_scaled = scaler.transform(weighted_playlist_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8bcf1",
   "metadata": {
    "id": "30f8bcf1"
   },
   "source": [
    "# Our Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TxxEBexbFTan",
   "metadata": {
    "id": "TxxEBexbFTan"
   },
   "source": [
    "In this section, we will be making different models using the different features and techniques we found earlier. Our baseline model will be a simple **K Nearest Neighbours algorithm** to recommend songs to users. While the novel approach is a combination of collaborative, content-based and deep learning approaches, the lack of available good datasets and hardware constraints made us stick to a **simpler, content-based filtering algorithm** as our recommender system.\n",
    "<br>\n",
    "<br>\n",
    "Our 5 models are as follows:\n",
    "1. Baseline model with using all features and default feature weights\n",
    "2. Baseline model with using all features and adjusted feature weights (based on insights from Part 2: Music Popularity Model)\n",
    "3. Baseline model with the worst feature weights dropped (based on insights from Part 2: Music Popularity Model)\n",
    "4. Baseline model with the Unweighted Autoencoder\n",
    "5. Baseline model with the Weighted Autoencoder\n",
    "\n",
    "We will not only be testing how well the models do with the dimensionality reduction, but also how well the model does if we add weights to the features, and seeing if it helps to improve the quality of our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oU0L0dqvwWBZ",
   "metadata": {
    "id": "oU0L0dqvwWBZ"
   },
   "source": [
    "### 1. Our baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rEOBLu9SLRJH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEOBLu9SLRJH",
    "outputId": "e94be54d-a177-407d-c271-d3aadc21a123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two of Us by Louis Tomlinson\n",
      "Let’s Go by Matt and Kim\n",
      "Sagittarius Superstar by COIN\n",
      "The Best Day (Taylor’s Version) by Taylor Swift\n",
      "Welcome To My Island by Caroline Polachek\n"
     ]
    }
   ],
   "source": [
    "# Initialize and Train the NearestNeighbors Model\n",
    "similarity_metric = 'cosine'\n",
    "\n",
    "# Fit and Train model\n",
    "nn_model = NearestNeighbors(n_neighbors=5, algorithm='auto', metric=similarity_metric)\n",
    "nn_model.fit(scaled_full_dataset_df.drop(['Track Name','artists'], axis=1).values)\n",
    "\n",
    "# Calculate the average features for the playlist\n",
    "average_features = scaled_playlist_features_df.drop(['Track Name','artists'], axis=1).mean(axis=0).to_numpy().reshape(1, -1)\n",
    "\n",
    "# Query the nearest neighbors model using the average feature vector\n",
    "distances, indices = nn_model.kneighbors(average_features)\n",
    "recommended_tracks = full_dataset_df.iloc[indices[0]]\n",
    "for i in range(5):\n",
    "    print(f\"{recommended_tracks['Track Name'].iloc[i]} by {recommended_tracks['artists'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zWvpYNNQwP59",
   "metadata": {
    "id": "zWvpYNNQwP59"
   },
   "source": [
    "### 2. Baseline model with weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d2533",
   "metadata": {},
   "source": [
    "Here we will be making use of our baseline model, but adding feature importances to our features through multiplying a feature that is more important with a value greater than one and a feature that is less important with a value less than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "PqB-MlDYwNcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqB-MlDYwNcf",
    "outputId": "bb8c911e-7d9f-453a-efa9-0f2bb6887363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tessellate by alt-J\n",
      "Shot in the Dark by John Mayer\n",
      "Harness Your Hopes - B-side by Pavement\n",
      "The Night Begins to Shine by B.E.R.\n",
      "Kenny by Still Woozy\n"
     ]
    }
   ],
   "source": [
    "# Set the similarity metric\n",
    "similarity_metric = 'cosine'\n",
    "\n",
    "weighted_scaled_full_dataset_df = scaled_full_dataset_df.copy()\n",
    "weighted_scaled_playlist_features_df = scaled_playlist_features_df.copy()\n",
    "    \n",
    "# Set weights\n",
    "weights = {\n",
    "    'genre_0': 3, 'genre_1': 3, 'genre_2': 3, 'genre_3': 3, 'genre_4': 3, 'genre_5': 3, 'genre_6': 3,\n",
    "    'explicit_False': 3, 'explicit_True': 3, 'release_year': 5, 'instrumentalness': 4,\n",
    "    'key_0': 0.3, 'key_1': 0.3, 'key_2': 0.3, 'key_3': 0.3, 'key_4': 0.3, 'key_5': 0.3, 'key_6': 0.3,\n",
    "    'key_7': 0.3, 'key_8': 0.3, 'key_9': 0.3, 'key_10': 0.3, 'key_11': 3, 'mode_0': 0.4, 'mode_1': 0.4,'danceability':0.3,'liveness':0.3\n",
    "}\n",
    "\n",
    "# Apply weights\n",
    "for feature, weight in weights.items():\n",
    "    weighted_scaled_full_dataset_df[feature] *= weight\n",
    "    weighted_scaled_playlist_features_df[feature] *= weight\n",
    "    \n",
    "\n",
    "# Initialize and Train the NearestNeighbors Model with the chosen metric\n",
    "nn_model = NearestNeighbors(n_neighbors=5, algorithm='auto', metric=similarity_metric)\n",
    "nn_model.fit(weighted_scaled_full_dataset_df.drop(['Track Name', 'artists'], axis=1).values)\n",
    "\n",
    "average_features = weighted_scaled_playlist_features_df.drop(['Track Name', 'artists'], axis=1).values.mean(axis=0).reshape(1, -1)\n",
    "# Query the nearest neighbors model using the average feature vector\n",
    "distances, indices = nn_model.kneighbors(average_features)\n",
    "\n",
    "recommended_tracks = full_dataset_df.iloc[indices[0]]\n",
    "for i in range(5):\n",
    "    print(f\"{recommended_tracks['Track Name'].iloc[i]} by {recommended_tracks['artists'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cXVMqJTSyx3J",
   "metadata": {
    "id": "cXVMqJTSyx3J"
   },
   "source": [
    "### 3. Baseline models with features dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351046eb",
   "metadata": {},
   "source": [
    "Here, we will only be using the top 5 features (excluding artists) that were found in the Music Popularity Model, namely genre, explicit, instrumentalness, loudness and release year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9BgZSuQFywSi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BgZSuQFywSi",
    "outputId": "e23c55cf-c7ac-4b13-9a28-c1b7405d3ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why Don't You by Cleo Sol\n",
      "The Night Begins to Shine by B.E.R.\n",
      "Call Me Up by daydreamers\n",
      "Afterthought by Joji\n",
      "Every Other Freckle by alt-J\n"
     ]
    }
   ],
   "source": [
    "# Set the similarity metric\n",
    "similarity_metric = 'cosine'\n",
    "\n",
    "# Initialize and Train the NearestNeighbors Model with the chosen metric\n",
    "nn_model = NearestNeighbors(n_neighbors=5, algorithm='auto', metric=similarity_metric)\n",
    "nn_model.fit(scaled_full_dataset_df[['genre_0', 'genre_1', 'genre_2', 'genre_3','genre_4','genre_5','genre_6','explicit_True','explicit_False','instrumentalness','loudness','release_year']].values)\n",
    "average_features = scaled_playlist_features_df[['genre_0', 'genre_1', 'genre_2', 'genre_3','genre_4','genre_5','genre_6','explicit_True','explicit_False','instrumentalness','loudness','release_year']].values.mean(axis=0).reshape(1, -1)\n",
    "# Query the nearest neighbors model using the average feature vector\n",
    "distances, indices = nn_model.kneighbors(average_features)\n",
    "recommended_tracks = full_dataset_df.iloc[indices[0]]\n",
    "for i in range(5):\n",
    "  print(f\"{recommended_tracks['Track Name'].iloc[i]} by {recommended_tracks['artists'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zlg1rrCuwcZs",
   "metadata": {
    "id": "Zlg1rrCuwcZs"
   },
   "source": [
    "### 4. Baseline model with the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a894e14",
   "metadata": {},
   "source": [
    "Our model, with the unweighted autoencoder used to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d0d07c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d0d07c4",
    "outputId": "66eeefce-c270-4af9-a241-3484b1ca60cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who's Lovin' You by The Jackson 5\n",
      "Dirt Off Your Shoulder by JAY-Z\n",
      "Keep Holding On by Avril Lavigne\n",
      "Swayed by How We Burn\n",
      "Pony by Ginuwine\n"
     ]
    }
   ],
   "source": [
    "# Set the similarity metric\n",
    "similarity_metric = 'cosine'\n",
    "\n",
    "# Initialize and Train the NearestNeighbors Model with the chosen metric\n",
    "nn_model = NearestNeighbors(n_neighbors=5, algorithm='auto', metric=similarity_metric)\n",
    "nn_model.fit(unweighted_full_encoded_scaled)\n",
    "\n",
    "\n",
    "average_features = unweighted_playlist_encoded_scaled.mean(axis=0).reshape(1, -1)\n",
    "# Query the nearest neighbors model using the average feature vector\n",
    "distances, indices = nn_model.kneighbors(average_features)\n",
    "recommended_tracks = full_dataset_df.iloc[indices[0]]\n",
    "for i in range(5):\n",
    "  print(f\"{recommended_tracks['Track Name'].iloc[i]} by {recommended_tracks['artists'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yMtsJ1URHL-x",
   "metadata": {
    "id": "yMtsJ1URHL-x"
   },
   "source": [
    "### 5. Baseline model with the autoencoder and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9578c6d",
   "metadata": {},
   "source": [
    "Our model, with the weighted autoencoder used to reduce dimensionality and to try and improve the quality of recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceb352a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "III. Urn by Childish Gambino\n",
      "AirplaneMode by BONES\n",
      "White by Frank Ocean\n",
      "From the Subway Train by Vansire\n",
      "Attracted to You by PinkPantheress\n"
     ]
    }
   ],
   "source": [
    "# Set the similarity metric, we chose cosine as seemed to give the best results\n",
    "similarity_metric = 'cosine' \n",
    "\n",
    "# Initialize and Train the NearestNeighbors Model with the chosen metric\n",
    "nn_model = NearestNeighbors(n_neighbors=5, algorithm='auto', metric=similarity_metric)\n",
    "nn_model.fit(weighted_full_encoded_scaled)\n",
    "\n",
    "# Calculate the average features for the playlist\n",
    "average_features = weighted_playlist_encoded_scaled.mean(axis=0).reshape(1, -1)\n",
    "\n",
    "# Query the nearest neighbors model using the average feature vector\n",
    "distances, indices = nn_model.kneighbors(average_features)\n",
    "recommended_tracks = full_dataset_df.iloc[indices[0]]\n",
    "for i in range(5):\n",
    "  print(f\"{recommended_tracks['Track Name'].iloc[i]} by {recommended_tracks['artists'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcAHOAIdNrJJ",
   "metadata": {
    "id": "bcAHOAIdNrJJ"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y1DvO01pNteX",
   "metadata": {
    "id": "y1DvO01pNteX"
   },
   "source": [
    "After making our models, we will be evaluating them based on user feedback. We got 10 users to try the recommender system, and got them to rate the quality of the top 5 recommendations. Here are our results:\n",
    "<br>\n",
    "1. Baseline model with adjusted weights: **7.04**\n",
    "2. Baseline model with the weighted autoencoder: 6.9\n",
    "3. Baseline model: 6.74\n",
    "4. Baseline model with the unweighted Autoencoder: 6.06\n",
    "5. Baseline models with worst features dropped: 4.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cFkEB-8dIIC3",
   "metadata": {
    "id": "cFkEB-8dIIC3"
   },
   "source": [
    "![title](img/survey.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R4a1mjK-Op8Y",
   "metadata": {
    "id": "R4a1mjK-Op8Y"
   },
   "source": [
    "# Data-driven Insights and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T7Cp899AOwt1",
   "metadata": {
    "id": "T7Cp899AOwt1"
   },
   "source": [
    "As you can see, while there are still areas for improvement for the quality of predictions across the board, the resultant recommendations were overall satisfactory. From our data, we can make a number of insights and recommendations to small-scale music streaming companies.\n",
    "\n",
    "1. **The baseline model with adjusted weights** based on features that we found to be important for song popularity **performed the best** amongst the five models. However, we also note that the use of **Weighted Autoencoders** can help **improve efficiency without significant performance cost** when we are making use of numerical metadata. It seems that for a small-scaled music recommender system, dimensionality reduction techniques like Weighted Autoencoder can be paired with feature enhancement/ model enhancement strategies to reach compromise between cost and performance. \n",
    "\n",
    "2. **Make use of a more robust recommender system**. While our results are not too bad, a simple content-based filtering algorithm is not as effective in dealing with **subjective preferences** compared to a model that uses **both content-based and collaborative filtering**. Implementation of collaborative filtering, which seeks to filter out music suggestions to a user based on how similar users react, can help to enhance our model further to personalise recommendations. \n",
    "\n",
    "3. **Broaden the types of data used**. We noticed that our system only uses **structured data** for training the recommender system. Novel approaches will make use of **lyric and audio data** to enhance feature selection and potentially improve the quality of recommendations to users. However, this will come at the expense of **more compute**. To balance this, for systems which take in unstructured data such as unstructured text-based lyric data and audio data, we recommend similar dimensionality reduction techniques such as the use of **Mel-Frequency Cepstral Coefficients (MFCCs) for audio data** [3], which is a method of encoding audio data and the use of **Singular Value Decomposition (SVD) for textual data**.[4]\n",
    "<br>\n",
    "<br>\n",
    "We believe that with these recommendations, a smaller company with less resources can make make a and a good and computationally efficient model to recommend songs to users. Some of our insights could also possibly help larger companies as well, to make their recommendations more robust.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fafdb5",
   "metadata": {},
   "source": [
    "### From Part 1: Genre Classification Model\n",
    "4. **Simpler models sometimes achieve better results**. The Multinomial Logistic Model beat the likes of sophisticated models such as XGBoost and Random Forest to give us the best classification metrics (e.g. accuracy, AOC score etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252638de",
   "metadata": {},
   "source": [
    "### From Part 2: Music Popularity Model\n",
    "5. **Popularity of a song** is more significantly influenced by the artists due to their accumulated fame and genre is shaped by one's preference in music. It is more interesting to note that **newer songs tend to be more popular** since they leave a stronger impression to current listeners. This is also boosted by the **digitalisation of music industry** as newer songs could be distributed more easily online. Presence of explicit lyrics could attract **eyeball attention** and influence the song popularity. Instrumentalness which measures the presence of vocal (higher implies lesser vocal content) is also important in deciding song popularity as most popular songs **generally contain vocals**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NXeOy7-W7Zmt",
   "metadata": {
    "id": "NXeOy7-W7Zmt"
   },
   "source": [
    "# Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FqsP26E87cN-",
   "metadata": {
    "id": "FqsP26E87cN-"
   },
   "source": [
    "[1] M. Schedl, ‘Deep Learning in Music Recommendation Systems’, Front. Appl. Math. Stat., vol. 5, doi: 10.3389/fams.2019.00044.\n",
    "<br>\n",
    "[2] F. Ricci, L. Rokach, and B. Shapira, Eds., Recommender Systems Handbook. New York, NY: Springer US, 2022. doi: 10.1007/978-1-0716-2197-4.\n",
    "<br>\n",
    "[3] V. Tiwari, \"MFCC and its applications in speaker recognition,\" International Journal on Emerging Technologies, vol. 1, no. 1, pp. 19-22, 2010.\n",
    "<br>\n",
    "[4] P. C. Hansen, \"The truncatedSVD as a method for regularization,\" BIT Numerical Mathematics, vol. 27, no. 4, pp. 534-553, 1987. doi: 10.1007/BF01937276."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnEzBy-C8bAO",
   "metadata": {
    "id": "qnEzBy-C8bAO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
